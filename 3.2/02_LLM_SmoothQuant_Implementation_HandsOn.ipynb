{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54eace91",
   "metadata": {},
   "source": [
    "# SmoothQuant Implementation: Accurate and Efficient Post-Training Quantization - Hands-On Practice\n",
    "\n",
    "## Introduction\n",
    "\n",
    "SmoothQuant is a post-training quantization technique that addresses the challenge of quantizing large language models (LLMs) by smoothing the activation outliers. This workshop implements the SmoothQuant method as described in the paper \"SmoothQuant: Accurate and Efficient Post-training Quantization for Large Language Models\" (Xiao et al., 2022).\n",
    "\n",
    "### Key Concepts:\n",
    "- **Problem**: Activation outliers in transformer models make quantization difficult\n",
    "- **Solution**: Migrate difficulty from activations to weights through mathematical equivalence\n",
    "- **Method**: Apply per-channel scaling to balance activation and weight quantization difficulties\n",
    "\n",
    "### Workshop Objectives:\n",
    "1. Load and analyze OPT-135M model weights and activations\n",
    "2. Visualize the distribution of weights and activations before SmoothQuant\n",
    "3. Implement the SmoothQuant algorithm\n",
    "4. Visualize the transformed distributions\n",
    "5. Evaluate model performance before and after quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e6f552",
   "metadata": {},
   "source": [
    "## 1. Environment Setup and Dependencies\n",
    "\n",
    "First, we install and import the necessary libraries for our implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233009ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install torch transformers datasets matplotlib numpy scipy tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90335a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from transformers import OPTForCausalLM, GPT2Tokenizer, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "print(\"🔥 HANDS-ON WORKSHOP: SmoothQuant Implementation\")\n",
    "print(\"📚 Complete the TODO exercises to learn SmoothQuant!\")\n",
    "print(\"💡 Look for TODO comments and fill in the missing code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87aca91",
   "metadata": {},
   "source": [
    "## 2. Model and Data Loading\n",
    "\n",
    "We load the OPT-135M model and prepare calibration data for analyzing activation patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d22657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OPT-135M model and tokenizer\n",
    "model_name = \"facebook/opt-125m\"  # Using 125M as it's more readily available\n",
    "print(f\"Loading model: {model_name}\")\n",
    "\n",
    "model = OPTForCausalLM.from_pretrained(model_name, torch_dtype=torch.float32)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully. Total parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e92451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare calibration dataset\n",
    "def prepare_calibration_data(tokenizer, num_samples=100, max_length=512):\n",
    "    \"\"\"Prepare calibration data from WikiText-2 dataset.\"\"\"\n",
    "    \n",
    "    # Load WikiText-2 dataset\n",
    "    dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"train\")\n",
    "    \n",
    "    calibration_texts = []\n",
    "    for i, example in enumerate(dataset):\n",
    "        if i >= num_samples:\n",
    "            break\n",
    "        text = example['text'].strip()\n",
    "        if len(text) > 50:  # Filter out very short texts\n",
    "            calibration_texts.append(text)\n",
    "    \n",
    "    # Tokenize the texts\n",
    "    inputs = tokenizer(\n",
    "        calibration_texts[:num_samples],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    return inputs\n",
    "\n",
    "# Prepare calibration data\n",
    "calibration_data = prepare_calibration_data(tokenizer, num_samples=50, max_length=256)\n",
    "print(f\"Calibration data shape: {calibration_data['input_ids'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c5ef8",
   "metadata": {},
   "source": [
    "## 3. Activation Collection and Analysis\n",
    "\n",
    "Before implementing SmoothQuant, we need to understand the distribution of activations in the model. We'll collect activations from linear layers during forward passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc78278d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationCollector:\n",
    "    \"\"\"Collects activations from specified layers during forward pass.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.activations = {}\n",
    "        self.hooks = []\n",
    "    \n",
    "    def hook_fn(self, name):\n",
    "        def hook(module, input, output):\n",
    "            # Store input activations (not output)\n",
    "            if isinstance(input, tuple):\n",
    "                activation = input[0].detach().cpu()\n",
    "            else:\n",
    "                activation = input.detach().cpu()\n",
    "            \n",
    "            if name not in self.activations:\n",
    "                self.activations[name] = []\n",
    "            self.activations[name].append(activation)\n",
    "        return hook\n",
    "    \n",
    "    def register_hooks(self, model, target_layers):\n",
    "        \"\"\"Register hooks on target layers.\"\"\"\n",
    "        for name, module in model.named_modules():\n",
    "            if any(target in name for target in target_layers):\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    hook = module.register_forward_hook(self.hook_fn(name))\n",
    "                    self.hooks.append(hook)\n",
    "                    print(f\"Registered hook on: {name}\")\n",
    "    \n",
    "    def remove_hooks(self):\n",
    "        \"\"\"Remove all registered hooks.\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks = []\n",
    "    \n",
    "    def get_aggregated_activations(self):\n",
    "        \"\"\"Aggregate collected activations.\"\"\"\n",
    "        aggregated = {}\n",
    "        for name, acts in self.activations.items():\n",
    "            # Concatenate all collected activations\n",
    "            concatenated = torch.cat(acts, dim=0)\n",
    "            aggregated[name] = concatenated\n",
    "        return aggregated\n",
    "\n",
    "# Initialize activation collector\n",
    "collector = ActivationCollector()\n",
    "\n",
    "# Target specific layers for analysis (focus on attention and MLP layers)\n",
    "target_layers = ['q_proj', 'k_proj', 'v_proj', 'out_proj', 'fc1', 'fc2']\n",
    "collector.register_hooks(model, target_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92243704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect activations by running forward passes\n",
    "print(\"Collecting activations...\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Process calibration data in smaller batches\n",
    "    batch_size = 8\n",
    "    num_batches = len(calibration_data['input_ids']) // batch_size\n",
    "    \n",
    "    for i in tqdm(range(num_batches)):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(calibration_data['input_ids']))\n",
    "        \n",
    "        batch_input_ids = calibration_data['input_ids'][start_idx:end_idx].to(device)\n",
    "        batch_attention_mask = calibration_data['attention_mask'][start_idx:end_idx].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids=batch_input_ids,\n",
    "            attention_mask=batch_attention_mask\n",
    "        )\n",
    "\n",
    "# Get aggregated activations\n",
    "activations_original = collector.get_aggregated_activations()\n",
    "collector.remove_hooks()\n",
    "\n",
    "print(f\"Collected activations from {len(activations_original)} layers\")\n",
    "for name, acts in activations_original.items():\n",
    "    print(f\"  {name}: {acts.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbee2a1a",
   "metadata": {},
   "source": [
    "## 4. Weight and Activation Distribution Analysis\n",
    "\n",
    "Now we analyze the distribution characteristics of weights and activations to understand the quantization challenges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8ec1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_distribution_stats(tensor, name):\n",
    "    \"\"\"Analyze statistical properties of tensor distributions.\"\"\"\n",
    "    \n",
    "    # Flatten tensor for analysis\n",
    "    flat_tensor = tensor.flatten()\n",
    "    \n",
    "    stats = {\n",
    "        'mean': float(torch.mean(flat_tensor)),\n",
    "        'std': float(torch.std(flat_tensor)),\n",
    "        'min': float(torch.min(flat_tensor)),\n",
    "        'max': float(torch.max(flat_tensor)),\n",
    "        'median': float(torch.median(flat_tensor)),\n",
    "        'q95': float(torch.quantile(flat_tensor, 0.95)),\n",
    "        'q99': float(torch.quantile(flat_tensor, 0.99)),\n",
    "        'abs_max': float(torch.max(torch.abs(flat_tensor)))\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{name} Distribution Statistics:\")\n",
    "    print(f\"  Mean: {stats['mean']:.6f}\")\n",
    "    print(f\"  Std:  {stats['std']:.6f}\")\n",
    "    print(f\"  Range: [{stats['min']:.6f}, {stats['max']:.6f}]\")\n",
    "    print(f\"  95th percentile: {stats['q95']:.6f}\")\n",
    "    print(f\"  99th percentile: {stats['q99']:.6f}\")\n",
    "    print(f\"  Absolute max: {stats['abs_max']:.6f}\")\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze activations\n",
    "activation_stats = {}\n",
    "for name, acts in activations_original.items():\n",
    "    if 'fc1' in name:  # Focus on one representative layer\n",
    "        activation_stats[name] = analyze_distribution_stats(acts, f\"Activations - {name}\")\n",
    "        break\n",
    "\n",
    "# Analyze weights from the same layer\n",
    "weight_stats = {}\n",
    "for name, module in model.named_modules():\n",
    "    if 'fc1' in name and isinstance(module, nn.Linear):\n",
    "        weight_stats[name] = analyze_distribution_stats(module.weight.data.cpu(), f\"Weights - {name}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b57c817",
   "metadata": {},
   "source": [
    "## 5. Pre-SmoothQuant Visualization\n",
    "\n",
    "We create 3D visualizations similar to those in the SmoothQuant paper, showing the distribution of weights and activations across channels and tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172575d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_3d_distribution_plot_matplotlib(tensor, title, max_channels=64, max_tokens=128):\n",
    "    \"\"\"Create 3D plot showing Channel x Token x Absolute Value distribution using matplotlib.\"\"\"\n",
    "    \n",
    "    # TODO: Reshape tensor to [batch*seq_len, channels] if needed\n",
    "    # HINT: Check if tensor has 3 dimensions, then reshape to 2D\n",
    "    if len(tensor.shape) == 3:\n",
    "        tensor = # Your code here - reshape to 2D\n",
    "    \n",
    "    # Sample data for visualization\n",
    "    num_tokens = min(tensor.shape[0], max_tokens)\n",
    "    num_channels = min(tensor.shape[1], max_channels)\n",
    "    \n",
    "    # TODO: Sample random indices for tokens and channels\n",
    "    # HINT: Use torch.randperm() to get random permutation, then slice [:num_tokens]\n",
    "    token_indices = # Your code here - random token indices\n",
    "    channel_indices = # Your code here - random channel indices\n",
    "    \n",
    "    # Extract sampled data\n",
    "    sampled_data = tensor[token_indices][:, channel_indices]\n",
    "    \n",
    "    # TODO: Compute absolute values\n",
    "    # HINT: Use torch.abs()\n",
    "    abs_values = # Your code here\n",
    "    \n",
    "    # Create meshgrid for 3D plot\n",
    "    channels = np.arange(num_channels)\n",
    "    tokens = np.arange(num_tokens)\n",
    "    C, T = np.meshgrid(channels, tokens)\n",
    "    \n",
    "    # Create 3D surface plot using matplotlib\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # TODO: Create surface plot\n",
    "    # HINT: Use ax.plot_surface() with C, T, abs_values.numpy(), and cmap='viridis'\n",
    "    surf = # Your code here - create surface plot\n",
    "    \n",
    "    # Customize plot\n",
    "    ax.set_xlabel('Channel Index')\n",
    "    ax.set_ylabel('Token Index') \n",
    "    ax.set_zlabel('Absolute Value')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Add colorbar\n",
    "    fig.colorbar(surf, ax=ax, shrink=0.5, aspect=5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Get representative layer data\n",
    "fc1_layer_name = None\n",
    "fc1_activations = None\n",
    "fc1_weights = None\n",
    "\n",
    "# TODO: Find FC1 layer in collected activations\n",
    "# HINT: Loop through activations_original.items() and check if 'fc1' in name\n",
    "for name, acts in activations_original.items():\n",
    "    if 'fc1' in name:\n",
    "        fc1_layer_name = name\n",
    "        fc1_activations = acts\n",
    "        break\n",
    "\n",
    "# TODO: Get corresponding weights from the model\n",
    "# HINT: Loop through model.named_modules() and find the layer with same name\n",
    "for name, module in model.named_modules():\n",
    "    if name == fc1_layer_name:\n",
    "        fc1_weights = # Your code here - get weight data and move to CPU\n",
    "        break\n",
    "\n",
    "print(f\"🎯 Analyzing layer: {fc1_layer_name}\")\n",
    "print(f\"📊 Activation shape: {fc1_activations.shape}\")\n",
    "print(f\"📊 Weight shape: {fc1_weights.shape}\")\n",
    "print(\"✅ Complete the TODOs above to prepare data for visualization!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895aa0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create 3D plots for original distributions\n",
    "print(\"Creating 3D visualizations for original distributions...\")\n",
    "\n",
    "# TODO: Plot original activations\n",
    "# HINT: Call create_3d_distribution_plot_matplotlib() with fc1_activations and appropriate title\n",
    "print(\"📊 Plotting original activations...\")\n",
    "fig_act_orig = # Your code here - create 3D plot for activations\n",
    "\n",
    "# TODO: Plot original weights (transpose to match channel dimension)\n",
    "# HINT: Use fc1_weights.T to transpose, then create 3D plot\n",
    "print(\"📊 Plotting original weights...\")\n",
    "fig_weight_orig = # Your code here - create 3D plot for weights (transposed)\n",
    "\n",
    "print(\"✅ Complete the TODOs above to visualize original distributions!\")\n",
    "print(\"🎯 Key observations to look for:\")\n",
    "print(\"  • Activation outliers (high peaks in certain channels)\")\n",
    "print(\"  • Weight distribution patterns\")\n",
    "print(\"  • These visualizations show WHY quantization is challenging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd67b85",
   "metadata": {},
   "source": [
    "## 6. SmoothQuant Algorithm Implementation - HANDS-ON PRACTICE\n",
    "\n",
    "Now we implement the core SmoothQuant algorithm. The key insight is to mathematically migrate quantization difficulty from activations to weights through per-channel scaling.\n",
    "\n",
    "**🔥 HANDS-ON PRACTICE**: Complete the missing parts of the SmoothQuant implementation below! Look for `# TODO:` comments and fill in the code.\n",
    "\n",
    "### Key Mathematical Concepts:\n",
    "- **Migration Formula**: For linear layer Y = XW^T, we apply scaling s to get Y = (X ⊘ s)(W ⊙ s)^T\n",
    "- **Scaling Factor**: s_j = (max|x_j|)^α where α controls migration strength\n",
    "- **Balance**: α = 0 (no smoothing) to α = 1 (full migration to weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57923d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothQuant:\n",
    "    \"\"\"Implementation of SmoothQuant algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self, alpha=0.5):\n",
    "        \"\"\"\n",
    "        Initialize SmoothQuant.\n",
    "        \n",
    "        Args:\n",
    "            alpha (float): Migration strength parameter. \n",
    "                          0 = no smoothing, 1 = full migration to weights\n",
    "        \"\"\"\n",
    "        self.alpha = alpha\n",
    "        self.scaling_factors = {}\n",
    "    \n",
    "    def compute_scaling_factors(self, activations):\n",
    "        \"\"\"\n",
    "        Compute per-channel scaling factors based on activation statistics.\n",
    "        \n",
    "        Args:\n",
    "            activations (torch.Tensor): Input activations [batch, seq_len, channels]\n",
    "        \n",
    "        Returns:\n",
    "            torch.Tensor: Scaling factors for each channel\n",
    "        \"\"\"\n",
    "        # TODO: Reshape activations to [batch*seq_len, channels] if needed\n",
    "        # HINT: Check if len(activations.shape) == 3, then reshape to 2D\n",
    "        if len(activations.shape) == 3:\n",
    "            activations = # Your code here - reshape to 2D\n",
    "        \n",
    "        # TODO: Compute per-channel maximum absolute values\n",
    "        # HINT: Use torch.max with dim=0 to get max along batch dimension\n",
    "        # HINT: torch.max returns (values, indices), so use [0] to get values\n",
    "        channel_max = # Your code here - compute max absolute values per channel\n",
    "        \n",
    "        # TODO: Compute scaling factors: s_j = (max|x_j|)^α\n",
    "        # HINT: Use torch.pow(channel_max, self.alpha)\n",
    "        scaling_factors = # Your code here - apply power of alpha\n",
    "        \n",
    "        # TODO: Avoid division by zero by clamping minimum value\n",
    "        # HINT: Use torch.clamp(scaling_factors, min=1e-8)\n",
    "        scaling_factors = # Your code here - clamp minimum value\n",
    "        \n",
    "        return scaling_factors\n",
    "    \n",
    "    def apply_smoothing(self, activations, weights, layer_name=None):\n",
    "        \"\"\"\n",
    "        Apply SmoothQuant transformation to activations and weights.\n",
    "        \n",
    "        For linear layer Y = XW^T:\n",
    "        - Scale activations: X' = X * diag(s^{-1})  [divide by scaling factors]\n",
    "        - Scale weights: W' = W * diag(s)           [multiply by scaling factors]\n",
    "        \n",
    "        Args:\n",
    "            activations (torch.Tensor): Input activations\n",
    "            weights (torch.Tensor): Layer weights\n",
    "            layer_name (str): Optional layer name for tracking\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (smoothed_activations, smoothed_weights, scaling_factors)\n",
    "        \"\"\"\n",
    "        # TODO: Compute scaling factors using the method above\n",
    "        scaling_factors = # Your code here - call compute_scaling_factors\n",
    "        \n",
    "        # Store scaling factors for tracking\n",
    "        if layer_name:\n",
    "            self.scaling_factors[layer_name] = scaling_factors\n",
    "        \n",
    "        # TODO: Apply scaling to activations (DIVIDE by scaling factors)\n",
    "        # HINT: Store original shape, reshape if needed, apply scaling, reshape back\n",
    "        original_shape = activations.shape\n",
    "        if len(original_shape) == 3:\n",
    "            activations_2d = activations.reshape(-1, original_shape[-1])\n",
    "        else:\n",
    "            activations_2d = activations\n",
    "        \n",
    "        # TODO: Scale activations by dividing by scaling factors\n",
    "        # HINT: Use scaling_factors.unsqueeze(0) to broadcast correctly\n",
    "        smoothed_activations_2d = # Your code here - divide activations by scaling factors\n",
    "        \n",
    "        # Reshape back to original shape\n",
    "        if len(original_shape) == 3:\n",
    "            smoothed_activations = smoothed_activations_2d.reshape(original_shape)\n",
    "        else:\n",
    "            smoothed_activations = smoothed_activations_2d\n",
    "        \n",
    "        # TODO: Apply scaling to weights (MULTIPLY by scaling factors)\n",
    "        # HINT: For linear layer weights [out_features, in_features], scale along input dimension\n",
    "        # HINT: Use scaling_factors.unsqueeze(0) to broadcast along output dimension\n",
    "        smoothed_weights = # Your code here - multiply weights by scaling factors\n",
    "        \n",
    "        return smoothed_activations, smoothed_weights, scaling_factors\n",
    "    \n",
    "    def get_migration_statistics(self, original_activations, original_weights, \n",
    "                               smoothed_activations, smoothed_weights):\n",
    "        \"\"\"\n",
    "        Compute statistics showing the effect of smoothing.\n",
    "        \"\"\"\n",
    "        stats = {}\n",
    "        \n",
    "        # TODO: Compute maximum absolute values for original and smoothed tensors\n",
    "        # HINT: Use torch.max(torch.abs(tensor.flatten())) for each tensor\n",
    "        orig_act_max = # Your code here - max abs value of original activations\n",
    "        smooth_act_max = # Your code here - max abs value of smoothed activations\n",
    "        \n",
    "        orig_weight_max = # Your code here - max abs value of original weights  \n",
    "        smooth_weight_max = # Your code here - max abs value of smoothed weights\n",
    "        \n",
    "        # TODO: Calculate reduction/increase ratios\n",
    "        stats['activation_max_reduction'] = # Your code here - orig_act_max / smooth_act_max\n",
    "        stats['weight_max_increase'] = # Your code here - smooth_weight_max / orig_weight_max\n",
    "        \n",
    "        stats['original_act_max'] = float(orig_act_max)\n",
    "        stats['smoothed_act_max'] = float(smooth_act_max)\n",
    "        stats['original_weight_max'] = float(orig_weight_max)\n",
    "        stats['smoothed_weight_max'] = float(smooth_weight_max)\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# TODO: Initialize SmoothQuant with α=0.5 (balanced smoothing)\n",
    "# HINT: Create an instance of SmoothQuant class with alpha=0.5\n",
    "smooth_quant = # Your code here - create SmoothQuant instance\n",
    "\n",
    "print(f\"Initialized SmoothQuant with α={smooth_quant.alpha}\")\n",
    "print(\"✅ Complete the TODOs above to implement the SmoothQuant algorithm!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24284dc",
   "metadata": {},
   "source": [
    "## 7. Apply SmoothQuant Transformation - HANDS-ON PRACTICE\n",
    "\n",
    "We now apply the SmoothQuant transformation to our representative layer and analyze the results.\n",
    "\n",
    "**🔥 HANDS-ON PRACTICE**: Complete the transformation application and analysis below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf4288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply SmoothQuant to the representative layer\n",
    "print(f\"Applying SmoothQuant to layer: {fc1_layer_name}\")\n",
    "\n",
    "# TODO: Apply smoothing using the smooth_quant instance\n",
    "# HINT: Call smooth_quant.apply_smoothing() with fc1_activations, fc1_weights, and fc1_layer_name\n",
    "smoothed_activations, smoothed_weights, scaling_factors = # Your code here\n",
    "\n",
    "print(f\"Original activations shape: {fc1_activations.shape}\")\n",
    "print(f\"Smoothed activations shape: {smoothed_activations.shape}\")\n",
    "print(f\"Original weights shape: {fc1_weights.shape}\")\n",
    "print(f\"Smoothed weights shape: {smoothed_weights.shape}\")\n",
    "print(f\"Scaling factors shape: {scaling_factors.shape}\")\n",
    "\n",
    "# TODO: Get migration statistics\n",
    "# HINT: Call smooth_quant.get_migration_statistics() with the four tensors\n",
    "migration_stats = # Your code here\n",
    "\n",
    "print(\"\\n🎯 SmoothQuant Migration Results:\")\n",
    "print(f\"  Activation outliers reduced by: {migration_stats['activation_max_reduction']:.3f}x\")\n",
    "print(f\"  Weight outliers increased by: {migration_stats['weight_max_increase']:.3f}x\")\n",
    "print(f\"  Original activation max: {migration_stats['original_act_max']:.6f}\")\n",
    "print(f\"  Smoothed activation max: {migration_stats['smoothed_act_max']:.6f}\")\n",
    "print(f\"  Original weight max: {migration_stats['original_weight_max']:.6f}\")\n",
    "print(f\"  Smoothed weight max: {migration_stats['smoothed_weight_max']:.6f}\")\n",
    "\n",
    "# TODO: Verify the mathematical equivalence (advanced challenge!)\n",
    "# HINT: Check that the matrix multiplication results are approximately equal\n",
    "# For Y = X @ W.T vs Y' = X' @ W'.T where X' and W' are smoothed versions\n",
    "print(\"\\n🔬 Mathematical Verification:\")\n",
    "print(\"Checking if Y = XW^T ≈ Y' = X'W'^T (mathematical equivalence)\")\n",
    "\n",
    "# Sample small batch for verification\n",
    "sample_size = min(10, fc1_activations.shape[0])\n",
    "sample_act = fc1_activations[:sample_size]\n",
    "sample_smooth_act = smoothed_activations[:sample_size]\n",
    "\n",
    "# TODO: Compute original output: Y = X @ W.T\n",
    "# HINT: Use torch.matmul() or @ operator\n",
    "original_output = # Your code here\n",
    "\n",
    "# TODO: Compute smoothed output: Y' = X' @ W'.T  \n",
    "# HINT: Use the smoothed activations and smoothed weights\n",
    "smoothed_output = # Your code here\n",
    "\n",
    "# TODO: Compute the difference between outputs\n",
    "# HINT: Use torch.mean(torch.abs(original_output - smoothed_output))\n",
    "output_difference = # Your code here\n",
    "\n",
    "print(f\"  Mean absolute difference between outputs: {float(output_difference):.8f}\")\n",
    "print(f\"  ✅ Outputs should be nearly identical (difference ≈ 0)\")\n",
    "\n",
    "if float(output_difference) < 1e-5:\n",
    "    print(\"  🎉 Mathematical equivalence verified!\")\n",
    "else:\n",
    "    print(\"  ⚠️  Check your implementation - outputs should be nearly identical\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e319bc0",
   "metadata": {},
   "source": [
    "### 💡 Hints and Solution Guidelines\n",
    "\n",
    "**For the SmoothQuant Implementation:**\n",
    "\n",
    "1. **Reshaping tensors**: When you have 3D activations [batch, seq_len, channels], reshape to 2D [batch*seq_len, channels] using `.reshape(-1, tensor.shape[-1])`\n",
    "\n",
    "2. **Computing channel maximums**: Use `torch.max(torch.abs(activations), dim=0)[0]` to get max absolute values per channel\n",
    "\n",
    "3. **Scaling factor formula**: The core SmoothQuant formula is `s_j = (max|x_j|)^α`\n",
    "\n",
    "4. **Applying scaling**: \n",
    "   - Activations: **divide** by scaling factors (reduce outliers)\n",
    "   - Weights: **multiply** by scaling factors (transfer difficulty)\n",
    "\n",
    "5. **Broadcasting**: Use `.unsqueeze(0)` to add batch dimension for proper broadcasting\n",
    "\n",
    "6. **Mathematical verification**: The key insight is that `X @ W.T` should equal `(X/s) @ (W*s).T` due to mathematical equivalence\n",
    "\n",
    "**Expected Results:**\n",
    "- Activation outliers should be reduced (factor > 1)\n",
    "- Weight outliers should increase (factor > 1) \n",
    "- Mathematical equivalence error should be < 1e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14698ef",
   "metadata": {},
   "source": [
    "## 8. Post-SmoothQuant Visualization\n",
    "\n",
    "We create visualizations of the smoothed distributions to compare with the original ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf91c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze smoothed distributions\n",
    "print(\"Analyzing smoothed distributions...\")\n",
    "\n",
    "smoothed_activation_stats = analyze_distribution_stats(\n",
    "    smoothed_activations, \n",
    "    f\"Smoothed Activations - {fc1_layer_name}\"\n",
    ")\n",
    "\n",
    "smoothed_weight_stats = analyze_distribution_stats(\n",
    "    smoothed_weights, \n",
    "    f\"Smoothed Weights - {fc1_layer_name}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a405886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3D plots for smoothed distributions\n",
    "print(\"Creating 3D visualizations for smoothed distributions...\")\n",
    "\n",
    "# Plot smoothed activations\n",
    "fig_act_smooth = create_3d_distribution_plot(\n",
    "    smoothed_activations, \n",
    "    \"Smoothed Activations Distribution (Channel × Token × Absolute Value)\"\n",
    ")\n",
    "fig_act_smooth.show()\n",
    "\n",
    "# Plot smoothed weights\n",
    "fig_weight_smooth = create_3d_distribution_plot(\n",
    "    smoothed_weights.T,\n",
    "    \"Smoothed Weights Distribution (Input Channel × Output Channel × Absolute Value)\"\n",
    ")\n",
    "fig_weight_smooth.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e12cea",
   "metadata": {},
   "source": [
    "## 9. Quantization Analysis - HANDS-ON PRACTICE\n",
    "\n",
    "Now we demonstrate the quantization benefits of SmoothQuant by comparing quantization errors before and after smoothing.\n",
    "\n",
    "**🔥 HANDS-ON PRACTICE**: Complete the quantization simulation and analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_tensor(tensor, bits=8, symmetric=True):\n",
    "    \"\"\"\n",
    "    Simulate quantization of a tensor.\n",
    "    \n",
    "    Args:\n",
    "        tensor (torch.Tensor): Input tensor\n",
    "        bits (int): Number of quantization bits\n",
    "        symmetric (bool): Whether to use symmetric quantization\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (quantized_tensor, quantization_error)\n",
    "    \"\"\"\n",
    "    if symmetric:\n",
    "        # TODO: Implement symmetric quantization\n",
    "        # HINT: Find max absolute value, compute scale, quantize and dequantize\n",
    "        max_val = # Your code here - find maximum absolute value\n",
    "        scale = # Your code here - compute scale factor using 2^(bits-1) - 1\n",
    "        quantized = # Your code here - quantize: round(tensor/scale) * scale\n",
    "    else:\n",
    "        # Asymmetric quantization (provided for reference)\n",
    "        min_val = torch.min(tensor)\n",
    "        max_val = torch.max(tensor)\n",
    "        scale = (max_val - min_val) / (2**bits - 1)\n",
    "        zero_point = -torch.round(min_val / scale)\n",
    "        quantized = (torch.round(tensor / scale) + zero_point - zero_point) * scale\n",
    "    \n",
    "    # TODO: Compute quantization error\n",
    "    # HINT: Use torch.mean(torch.abs(tensor - quantized))\n",
    "    error = # Your code here - compute mean absolute error\n",
    "    \n",
    "    return quantized, error\n",
    "\n",
    "def analyze_quantization_impact(original_tensor, smoothed_tensor, name, bits=8):\n",
    "    \"\"\"\n",
    "    Compare quantization impact on original vs smoothed tensors.\n",
    "    \"\"\"\n",
    "    # TODO: Quantize original tensor\n",
    "    # HINT: Call quantize_tensor() function\n",
    "    quant_orig, error_orig = # Your code here\n",
    "    \n",
    "    # TODO: Quantize smoothed tensor  \n",
    "    # HINT: Call quantize_tensor() function\n",
    "    quant_smooth, error_smooth = # Your code here\n",
    "    \n",
    "    # TODO: Calculate improvement (error reduction ratio)\n",
    "    # HINT: Divide original error by smoothed error\n",
    "    error_reduction = # Your code here\n",
    "    \n",
    "    print(f\"\\n📊 {name} Quantization Analysis ({bits}-bit):\")\n",
    "    print(f\"  Original quantization error: {float(error_orig):.6f}\")\n",
    "    print(f\"  Smoothed quantization error: {float(error_smooth):.6f}\")\n",
    "    print(f\"  Error reduction: {float(error_reduction):.3f}x\")\n",
    "    \n",
    "    # Color-coded feedback\n",
    "    if error_reduction > 1.1:\n",
    "        print(f\"  ✅ Great! SmoothQuant improved quantization\")\n",
    "    elif error_reduction > 0.9:\n",
    "        print(f\"  ⚠️  Slight improvement or similar performance\")\n",
    "    else:\n",
    "        print(f\"  ❌ Check implementation - should see improvement\")\n",
    "    \n",
    "    return {\n",
    "        'original_error': float(error_orig),\n",
    "        'smoothed_error': float(error_smooth),\n",
    "        'error_reduction': float(error_reduction)\n",
    "    }\n",
    "\n",
    "# TODO: Analyze quantization impact on activations\n",
    "# HINT: Call analyze_quantization_impact() with fc1_activations and smoothed_activations\n",
    "activation_quant_results = # Your code here\n",
    "\n",
    "# TODO: Analyze quantization impact on weights\n",
    "# HINT: Call analyze_quantization_impact() with fc1_weights and smoothed_weights  \n",
    "weight_quant_results = # Your code here\n",
    "\n",
    "print(\"\\n🎯 Key Insights:\")\n",
    "print(\"• Activations should show significant error reduction (SmoothQuant's main benefit)\")\n",
    "print(\"• Weights may show increased error (this is expected - difficulty migrated here)\")\n",
    "print(\"• Overall system benefits from easier activation quantization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db792b28",
   "metadata": {},
   "source": [
    "## 10. Model Performance Evaluation\n",
    "\n",
    "Finally, we evaluate the impact of SmoothQuant on model performance by comparing perplexity before and after applying the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb200071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_perplexity(model, tokenizer, eval_texts, max_length=256):\n",
    "    \"\"\"\n",
    "    Evaluate model perplexity on given texts.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for text in eval_texts:\n",
    "            # Tokenize\n",
    "            inputs = tokenizer(\n",
    "                text, \n",
    "                return_tensors=\"pt\", \n",
    "                max_length=max_length, \n",
    "                truncation=True\n",
    "            )\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(**inputs, labels=inputs['input_ids'])\n",
    "            \n",
    "            # Accumulate loss\n",
    "            total_loss += outputs.loss.item() * inputs['input_ids'].numel()\n",
    "            total_tokens += inputs['input_ids'].numel()\n",
    "    \n",
    "    # Calculate perplexity\n",
    "    avg_loss = total_loss / total_tokens\n",
    "    perplexity = torch.exp(torch.tensor(avg_loss))\n",
    "    \n",
    "    return float(perplexity)\n",
    "\n",
    "# Prepare evaluation texts\n",
    "eval_dataset = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\", split=\"validation\")\n",
    "eval_texts = [example['text'] for example in eval_dataset if len(example['text'].strip()) > 50][:20]\n",
    "\n",
    "print(f\"Evaluating on {len(eval_texts)} validation texts...\")\n",
    "\n",
    "# Evaluate original model\n",
    "original_perplexity = evaluate_perplexity(model, tokenizer, eval_texts)\n",
    "print(f\"Original model perplexity: {original_perplexity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5c6ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a modified model with SmoothQuant applied\n",
    "def apply_smoothquant_to_model(model, smooth_quant_instance):\n",
    "    \"\"\"\n",
    "    Apply SmoothQuant transformations to the entire model.\n",
    "    Note: This is a simplified version for demonstration.\n",
    "    \"\"\"\n",
    "    modified_model = model  # In practice, you'd create a copy\n",
    "    \n",
    "    # For demonstration, we'll just show that the scaling factors have been computed\n",
    "    print(\"SmoothQuant scaling factors computed for layers:\")\n",
    "    for layer_name, factors in smooth_quant_instance.scaling_factors.items():\n",
    "        print(f\"  {layer_name}: {factors.shape}\")\n",
    "    \n",
    "    return modified_model\n",
    "\n",
    "# Apply SmoothQuant (simplified for demonstration)\n",
    "smoothed_model = apply_smoothquant_to_model(model, smooth_quant)\n",
    "\n",
    "print(\"\\nSmoothQuant transformation applied successfully!\")\n",
    "print(\"In a full implementation, you would:\")\n",
    "print(\"1. Apply scaling to all linear layers\")\n",
    "print(\"2. Modify the model architecture to include scaling\")\n",
    "print(\"3. Re-evaluate perplexity with the modified model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01863c70",
   "metadata": {},
   "source": [
    "## 11. Results Summary and Comparison\n",
    "\n",
    "Let's summarize our findings and create comparison visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b56d746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary comparison plots using matplotlib\n",
    "def create_comparison_plot_matplotlib():\n",
    "    \"\"\"Create side-by-side comparison plots using matplotlib.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "    fig.suptitle(\"SmoothQuant Results Summary\", fontsize=16)\n",
    "    \n",
    "    # Activation histograms\n",
    "    orig_act_flat = fc1_activations.flatten().numpy()\n",
    "    smooth_act_flat = smoothed_activations.flatten().numpy()\n",
    "    \n",
    "    axes[0, 0].hist(orig_act_flat, bins=50, alpha=0.7, label=\"Original\")\n",
    "    axes[0, 0].hist(smooth_act_flat, bins=50, alpha=0.7, label=\"Smoothed\")\n",
    "    axes[0, 0].set_title(\"Activation Distribution (Before vs After)\")\n",
    "    axes[0, 0].set_xlabel(\"Value\")\n",
    "    axes[0, 0].set_ylabel(\"Frequency\")\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # Weight histograms\n",
    "    orig_weight_flat = fc1_weights.flatten().numpy()\n",
    "    smooth_weight_flat = smoothed_weights.flatten().numpy()\n",
    "    \n",
    "    axes[0, 1].hist(orig_weight_flat, bins=50, alpha=0.7, label=\"Original\")\n",
    "    axes[0, 1].hist(smooth_weight_flat, bins=50, alpha=0.7, label=\"Smoothed\")\n",
    "    axes[0, 1].set_title(\"Weight Distribution (Before vs After)\")\n",
    "    axes[0, 1].set_xlabel(\"Value\")\n",
    "    axes[0, 1].set_ylabel(\"Frequency\")\n",
    "    axes[0, 1].legend()\n",
    "    \n",
    "    # Quantization error comparison\n",
    "    axes[1, 0].bar([\"Activations\", \"Weights\"], [activation_quant_results['original_error'], weight_quant_results['original_error']], alpha=0.7, label=\"Original Error\")\n",
    "    axes[1, 0].bar([\"Activations\", \"Weights\"], [activation_quant_results['smoothed_error'], weight_quant_results['smoothed_error']], alpha=0.7, label=\"Smoothed Error\")\n",
    "    axes[1, 0].set_title(\"Quantization Error Comparison\")\n",
    "    axes[1, 0].set_ylabel(\"Error\")\n",
    "    axes[1, 0].legend()\n",
    "    \n",
    "    # Migration statistics\n",
    "    axes[1, 1].bar([\"Act. Max Reduction\", \"Weight Max Increase\"], [migration_stats['activation_max_reduction'], migration_stats['weight_max_increase']], alpha=0.7, label=\"Migration Effect\")\n",
    "    axes[1, 1].set_title(\"Migration Statistics\")\n",
    "    axes[1, 1].set_ylabel(\"Effect\")\n",
    "    axes[1, 1].legend()\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()\n",
    "    \n",
    "# Create and show comparison plot using matplotlib\n",
    "create_comparison_plot_matplotlib()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a3d1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SMOOTHQUANT IMPLEMENTATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nModel Analyzed: {model_name}\")\n",
    "print(f\"Target Layer: {fc1_layer_name}\")\n",
    "print(f\"Smoothing Parameter (α): {smooth_quant.alpha}\")\n",
    "\n",
    "print(\"\\nMigration Results:\")\n",
    "print(f\"   • Activation outliers reduced by: {migration_stats['activation_max_reduction']:.2f}x\")\n",
    "print(f\"   • Weight outliers increased by: {migration_stats['weight_max_increase']:.2f}x\")\n",
    "\n",
    "print(\"\\nQuantization Improvements:\")\n",
    "print(f\"   • Activation quantization error reduced by: {activation_quant_results['error_reduction']:.2f}x\")\n",
    "print(f\"   • Weight quantization error changed by: {weight_quant_results['error_reduction']:.2f}x\")\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"   • SmoothQuant successfully migrates quantization difficulty from activations to weights\")\n",
    "print(\"   • Activation outliers are smoothed, making them easier to quantize\")\n",
    "print(\"   • The mathematical equivalence preserves model functionality\")\n",
    "print(\"   • 3D visualizations clearly show the distribution changes\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Workshop completed successfully! 🎉\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
