{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f4c21b9",
   "metadata": {},
   "source": [
    "# Module 5.4: Real-Time Inference and Alerts - HANDS-ON VERSION\n",
    "\n",
    "## Combined Case Study: Cybersecurity, Edge AI and Autonomous Driving\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ HANDS-ON LEARNING OBJECTIVES\n",
    "\n",
    "**‚ö†Ô∏è CODE COMPLETION WORKSHOP:** This notebook provides hands-on practice implementing a complete real-time anomaly detection system. You'll build each component with guided TODO exercises.\n",
    "\n",
    "**üìö WHAT YOU'LL LEARN:**\n",
    "- Real-time data streaming simulation techniques\n",
    "- PyTorch model inference in production environments  \n",
    "- Alert management systems with cooldown mechanisms\n",
    "- Performance monitoring and visualization for Edge AI\n",
    "- End-to-end real-time cybersecurity pipeline development\n",
    "\n",
    "**üöÄ PRACTICAL SKILLS:**\n",
    "- Implement streaming data processors\n",
    "- Build inference engines with performance tracking\n",
    "- Create intelligent alerting systems\n",
    "- Design monitoring dashboards for live systems\n",
    "- Handle real-time anomaly detection workflows\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Simulate **real-time inference** on a connected autonomous vehicle using the trained multimodal Edge AI model from Notebook 02.\n",
    "\n",
    "The simulation will:\n",
    "- Continuously receive **vehicle telemetry data** and **network traffic data** in a streaming-like fashion\n",
    "- Predict anomalies in real-time using our PyTorch model\n",
    "- Trigger different alerts depending on the type of anomaly detected\n",
    "- Log and visualize alerts for system monitoring\n",
    "\n",
    "---\n",
    "\n",
    "## Key Features\n",
    "\n",
    "### **Real-Time Processing Pipeline:**\n",
    "```\n",
    "Streaming Data ‚Üí Preprocessing ‚Üí Model Inference ‚Üí Alert System ‚Üí Logging\n",
    "```\n",
    "\n",
    "### **Alert Types:**\n",
    "- **Physical Anomaly**: Vehicle sensor/behavior issues\n",
    "- **Network Anomaly**: Cybersecurity threats\n",
    "- **Normal Operation**: System functioning correctly\n",
    "\n",
    "### **System Components:**\n",
    "1. **Model Loading**: Import trained PyTorch model and preprocessors (SKIP - Step 1)\n",
    "2. **Data Streaming**: Simulate real-time data ingestion (HANDS-ON - Step 2)\n",
    "3. **Real-Time Inference**: Continuous prediction pipeline (HANDS-ON - Step 3)\n",
    "4. **Alert Management**: Smart alerting with cooldown mechanisms (HANDS-ON - Step 4)\n",
    "5. **Logging & Visualization**: Monitor system performance (HANDS-ON - Step 5-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f28895a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import json\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "# PyTorch libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Configuration\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(\"Real-Time Inference System - Libraries Loaded!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"System ready for real-time anomaly detection!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e64be97",
   "metadata": {},
   "source": [
    "## Step 1: Model Recriation and weight loading\n",
    "\n",
    "Create the model architecture and load the pre-trained weights from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10efbcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model architecture (must match Notebook 02)\n",
    "class MultimodalEdgeAI(nn.Module):\n",
    "    \"\"\"\n",
    "    Large MobileNetV2-sized multimodal neural network for enhanced performance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, vehicle_input_size, network_input_size, num_classes=3):\n",
    "        super(MultimodalEdgeAI, self).__init__()\n",
    "        \n",
    "        # Large Vehicle telemetry branch (6 layers)\n",
    "        self.vehicle_branch = nn.Sequential(\n",
    "            nn.Linear(vehicle_input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16)\n",
    "        )\n",
    "        \n",
    "        # Large Network traffic branch (6 layers)\n",
    "        self.network_branch = nn.Sequential(\n",
    "            nn.Linear(network_input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.15),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16)\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "        \n",
    "        # Large Fusion layers (7 layers)\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(32, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.35),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(16, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, vehicle_input, network_input):\n",
    "        vehicle_features = self.vehicle_branch(vehicle_input)\n",
    "        network_features = self.network_branch(network_input)\n",
    "        fused_features = torch.cat([vehicle_features, network_features], dim=1)\n",
    "        attention_weights = self.attention(fused_features)\n",
    "        attended_features = fused_features * attention_weights\n",
    "        output = self.fusion(attended_features)\n",
    "        return output\n",
    "\n",
    "def load_trained_model_and_preprocessors():\n",
    "    \"\"\"\n",
    "    Load the trained model and preprocessing components\n",
    "    \n",
    "    Returns:\n",
    "    - model: Loaded PyTorch model\n",
    "    - vehicle_scaler: StandardScaler for vehicle features\n",
    "    - network_scaler: StandardScaler for network features\n",
    "    - feature_columns: Dictionary with feature column names\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Loading trained model and preprocessors...\")\n",
    "    \n",
    "    # Load the dataset to get feature information\n",
    "    try:\n",
    "        dataset = pd.read_csv('combined_dataset.csv')\n",
    "        print(f\"Dataset loaded: {dataset.shape}\")\n",
    "        \n",
    "        # Identify feature columns\n",
    "        vehicle_features = [col for col in dataset.columns if col.startswith('veh_')]\n",
    "        network_features = [col for col in dataset.columns if col.startswith('net_')]\n",
    "        \n",
    "        print(f\"   Vehicle features: {len(vehicle_features)}\")\n",
    "        print(f\"   Network features: {len(network_features)}\")\n",
    "        \n",
    "        # Initialize model with correct input sizes\n",
    "        model = MultimodalEdgeAI(\n",
    "            vehicle_input_size=len(vehicle_features),\n",
    "            network_input_size=len(network_features),\n",
    "            num_classes=3\n",
    "        )\n",
    "        \n",
    "        # Try to load trained model weights\n",
    "        try:\n",
    "            model.load_state_dict(torch.load('best_improved_model.pth', map_location=device))\n",
    "            print(\"Trained model weights loaded successfully!\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"No trained model found. Using randomly initialized model.\")\n",
    "            print(\"   Please run Notebook 02 first to train the model.\")\n",
    "        \n",
    "        model.to(device)\n",
    "        model.eval()  # Set to evaluation mode\n",
    "        \n",
    "        # Create and fit scalers using the full dataset\n",
    "        vehicle_scaler = StandardScaler()\n",
    "        network_scaler = StandardScaler()\n",
    "        \n",
    "        X_vehicle = dataset[vehicle_features].values\n",
    "        X_network = dataset[network_features].values\n",
    "        \n",
    "        # Handle missing values\n",
    "        from sklearn.impute import SimpleImputer\n",
    "        imputer_vehicle = SimpleImputer(strategy='median')\n",
    "        imputer_network = SimpleImputer(strategy='median')\n",
    "        \n",
    "        X_vehicle = imputer_vehicle.fit_transform(X_vehicle)\n",
    "        X_network = imputer_network.fit_transform(X_network)\n",
    "        \n",
    "        # Fit scalers\n",
    "        vehicle_scaler.fit(X_vehicle)\n",
    "        network_scaler.fit(X_network)\n",
    "        \n",
    "        feature_columns = {\n",
    "            'vehicle': vehicle_features,\n",
    "            'network': network_features\n",
    "        }\n",
    "        \n",
    "        print(\"Preprocessors initialized successfully!\")\n",
    "        \n",
    "        return model, vehicle_scaler, network_scaler, feature_columns, dataset\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Dataset not found! Please run Notebook 01 first.\")\n",
    "        raise FileNotFoundError(\"combined_dataset.csv not found\")\n",
    "\n",
    "# Load model and preprocessors\n",
    "model, vehicle_scaler, network_scaler, feature_columns, reference_dataset = load_trained_model_and_preprocessors()\n",
    "\n",
    "# Model information\n",
    "param_count = sum(p.numel() for p in model.parameters())\n",
    "model_size_mb = param_count * 4 / (1024 * 1024)\n",
    "\n",
    "print(f\"\\nModel Information:\")\n",
    "print(f\"   Parameters: {param_count:,}\")\n",
    "print(f\"   Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"   Vehicle features: {len(feature_columns['vehicle'])}\")\n",
    "print(f\"   Network features: {len(feature_columns['network'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74a6c59",
   "metadata": {},
   "source": [
    "## Step 2: Real-Time Data Streaming Simulation - HANDS-ON PRACTICE\n",
    "\n",
    "**üéØ LEARNING OBJECTIVE:** Learn to build real-time data streaming systems for continuous anomaly detection.\n",
    "\n",
    "**‚ö†Ô∏è CODE COMPLETION EXERCISE:** You'll implement streaming data simulation, anomaly injection, and batch generation for real-time processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f15137",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeDataStreamer:\n",
    "    \"\"\"\n",
    "    Simulates real-time streaming of vehicle telemetry and network traffic data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, vehicle_features, network_features, anomaly_rate=0.15):\n",
    "        # TODO: Initialize data streamer attributes\n",
    "        # HINT: Store dataset, features, anomaly rate, and current position\n",
    "        self.dataset = # TODO: Store dataset\n",
    "        self.vehicle_features = # TODO: Store vehicle feature names\n",
    "        self.network_features = # TODO: Store network feature names\n",
    "        self.anomaly_rate = # TODO: Store anomaly injection rate\n",
    "        self.current_index = 0\n",
    "        # TODO: Calculate total number of samples\n",
    "        # HINT: Use len(dataset)\n",
    "        self.total_samples = # TODO: Get dataset length\n",
    "        \n",
    "        # TODO: Create class mapping dictionary\n",
    "        # HINT: {0: 'Normal', 1: 'Physical Anomaly', 2: 'Network Anomaly'}\n",
    "        self.class_names = # TODO: Define class name mapping\n",
    "        \n",
    "        print(f\"Data Streamer initialized:\")\n",
    "        print(f\"   Total samples available: {self.total_samples:,}\")\n",
    "        print(f\"   Anomaly injection rate: {self.anomaly_rate:.1%}\")\n",
    "    \n",
    "    def get_next_sample(self, inject_anomaly=None):\n",
    "        \"\"\"\n",
    "        Get the next data sample from the stream\n",
    "        \n",
    "        Parameters:\n",
    "        - inject_anomaly: Force specific anomaly type (0, 1, 2) or None for natural\n",
    "        \n",
    "        Returns:\n",
    "        - sample_data: Dictionary with vehicle/network features and metadata\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO: Handle dataset wraparound when reaching the end\n",
    "        # HINT: Reset current_index to 0 if it reaches total_samples\n",
    "        if self.current_index >= self.total_samples:\n",
    "            self.current_index = # TODO: Reset index to beginning\n",
    "        \n",
    "        # TODO: Get sample from dataset at current index\n",
    "        # HINT: Use self.dataset.iloc[self.current_index].copy()\n",
    "        sample = # TODO: Get current sample from dataset\n",
    "        # TODO: Increment current index for next call\n",
    "        self.current_index += 1\n",
    "        \n",
    "        # TODO: Extract vehicle and network features from sample\n",
    "        # HINT: Use sample[self.vehicle_features].values and sample[self.network_features].values\n",
    "        vehicle_data = # TODO: Extract vehicle features as numpy array\n",
    "        network_data = # TODO: Extract network features as numpy array\n",
    "        # TODO: Get true label, default to 0 if not present\n",
    "        # HINT: Use sample['label'] if 'label' in sample else 0\n",
    "        true_label = # TODO: Get true label from sample\n",
    "        \n",
    "        # TODO: Handle anomaly injection\n",
    "        if inject_anomaly is not None:\n",
    "            # TODO: Override true label with injected anomaly type\n",
    "            true_label = # TODO: Set true_label to inject_anomaly\n",
    "            if inject_anomaly == 1:  # Physical anomaly\n",
    "                # TODO: Inject physical anomaly into vehicle data\n",
    "                # HINT: Call self._inject_physical_anomaly(vehicle_data)\n",
    "                vehicle_data = # TODO: Inject physical anomaly\n",
    "            elif inject_anomaly == 2:  # Network anomaly\n",
    "                # TODO: Inject network anomaly into network data\n",
    "                # HINT: Call self._inject_network_anomaly(network_data)\n",
    "                network_data = # TODO: Inject network anomaly\n",
    "        \n",
    "        # TODO: Create sample data dictionary\n",
    "        # HINT: Include timestamp, features, labels, and sample_id\n",
    "        sample_data = {\n",
    "            'timestamp': # TODO: Get current timestamp using datetime.now()\n",
    "            'vehicle_features': # TODO: Add vehicle_data\n",
    "            'network_features': # TODO: Add network_data\n",
    "            'true_label': # TODO: Add true_label\n",
    "            'true_label_name': # TODO: Get class name using self.class_names[true_label]\n",
    "            'sample_id': # TODO: Add sample ID (current_index - 1)\n",
    "        }\n",
    "        \n",
    "        return sample_data\n",
    "    \n",
    "    def _inject_physical_anomaly(self, vehicle_data):\n",
    "        \"\"\"Inject physical anomaly into vehicle telemetry\"\"\"\n",
    "        # TODO: Create a copy of vehicle data to avoid modifying original\n",
    "        # HINT: Use vehicle_data.copy()\n",
    "        vehicle_data = # TODO: Copy vehicle data\n",
    "        \n",
    "        # TODO: Simulate brake system anomaly\n",
    "        # HINT: Modify first feature to extreme brake pressure (multiply by 2.5, min 100)\n",
    "        if len(vehicle_data) > 0:\n",
    "            vehicle_data[0] = # TODO: Set extreme brake pressure\n",
    "        \n",
    "        # TODO: Simulate tire pressure anomaly  \n",
    "        # HINT: Modify fourth feature to low tire pressure (multiply by 0.3, max 10)\n",
    "        if len(vehicle_data) > 3:\n",
    "            vehicle_data[3] = # TODO: Set low tire pressure\n",
    "        \n",
    "        return vehicle_data\n",
    "    \n",
    "    def _inject_network_anomaly(self, network_data):\n",
    "        \"\"\"Inject network anomaly into network traffic\"\"\"\n",
    "        # TODO: Create a copy of network data\n",
    "        network_data = # TODO: Copy network data\n",
    "        \n",
    "        # TODO: Simulate suspicious network activity - high packet count\n",
    "        # HINT: Modify first feature (multiply by 3.0, min 1000)\n",
    "        if len(network_data) > 0:\n",
    "            network_data[0] = # TODO: Set high packet count\n",
    "        \n",
    "        # TODO: Simulate large payload size\n",
    "        # HINT: Modify third feature (multiply by 2.0, min 500)\n",
    "        if len(network_data) > 2:\n",
    "            network_data[2] = # TODO: Set large payload size\n",
    "        \n",
    "        return network_data\n",
    "    \n",
    "    def generate_streaming_batch(self, batch_size=10, include_anomalies=True):\n",
    "        \"\"\"\n",
    "        Generate a batch of streaming samples\n",
    "        \n",
    "        Parameters:\n",
    "        - batch_size: Number of samples to generate\n",
    "        - include_anomalies: Whether to include some anomalies\n",
    "        \n",
    "        Returns:\n",
    "        - List of sample data dictionaries\n",
    "        \"\"\"\n",
    "        # TODO: Initialize empty batch list\n",
    "        batch = # TODO: Create empty list for batch\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            # TODO: Determine if we should inject an anomaly\n",
    "            inject_anomaly = None\n",
    "            if include_anomalies and # TODO: Check random probability < self.anomaly_rate:\n",
    "                # TODO: Randomly choose anomaly type (1 or 2)\n",
    "                # HINT: Use np.random.choice([1, 2]) for Physical or Network anomaly\n",
    "                inject_anomaly = # TODO: Choose random anomaly type\n",
    "            \n",
    "            # TODO: Get next sample with potential anomaly injection\n",
    "            # HINT: Call self.get_next_sample(inject_anomaly=inject_anomaly)\n",
    "            sample = # TODO: Get next sample\n",
    "            # TODO: Add sample to batch\n",
    "            batch.append(# TODO: Add sample)\n",
    "            \n",
    "            # TODO: Add small delay to simulate real-time streaming\n",
    "            # HINT: Use time.sleep with a small value like 0.001\n",
    "            # TODO: Add streaming delay\n",
    "        \n",
    "        return batch\n",
    "\n",
    "# TODO: Initialize data streamer\n",
    "print(\"Initializing real-time data streamer...\")\n",
    "# TODO: Create RealTimeDataStreamer instance\n",
    "# HINT: Use reference_dataset, feature_columns['vehicle'], feature_columns['network']\n",
    "data_streamer = # TODO: Create data streamer instance\n",
    "\n",
    "# TODO: Test the streamer\n",
    "print(\"\\\\nTesting data streamer:\")\n",
    "# TODO: Generate test batch of 5 samples\n",
    "# HINT: Call data_streamer.generate_streaming_batch(batch_size=5)\n",
    "test_batch = # TODO: Generate test batch\n",
    "for i, sample in enumerate(test_batch):\n",
    "    print(f\"   Sample {i+1}: {sample['true_label_name']} at {sample['timestamp'].strftime('%H:%M:%S')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a011a7fc",
   "metadata": {},
   "source": [
    "## Step 3: Real-Time Inference Engine - HANDS-ON PRACTICE\n",
    "\n",
    "**üéØ LEARNING OBJECTIVE:** Learn to build high-performance real-time inference systems for production Edge AI applications.\n",
    "\n",
    "**‚ö†Ô∏è CODE COMPLETION EXERCISE:** You'll implement preprocessing pipelines, model inference, performance tracking, and prediction result formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04181d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeInferenceEngine:\n",
    "    \"\"\"\n",
    "    Real-time inference engine for multimodal anomaly detection\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, vehicle_scaler, network_scaler, confidence_threshold=0.7):\n",
    "        # TODO: Initialize inference engine attributes\n",
    "        # HINT: Store model, scalers, threshold, and class names\n",
    "        self.model = # TODO: Store model\n",
    "        self.vehicle_scaler = # TODO: Store vehicle scaler\n",
    "        self.network_scaler = # TODO: Store network scaler\n",
    "        self.confidence_threshold = # TODO: Store confidence threshold\n",
    "        \n",
    "        # TODO: Define class name mapping\n",
    "        # HINT: {0: 'Normal', 1: 'Physical Anomaly', 2: 'Network Anomaly'}\n",
    "        self.class_names = # TODO: Define class name mapping\n",
    "        \n",
    "        # TODO: Initialize performance tracking with deque for fixed-size history\n",
    "        # HINT: Use deque(maxlen=1000) to track last 1000 inference times and predictions\n",
    "        self.inference_times = # TODO: Create deque for inference times\n",
    "        self.predictions_history = # TODO: Create deque for predictions history\n",
    "        \n",
    "        print(f\"Inference Engine initialized:\")\n",
    "        print(f\"   Model: {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "        print(f\"   Confidence threshold: {confidence_threshold}\")\n",
    "        print(f\"   Device: {device}\")\n",
    "    \n",
    "    def preprocess_sample(self, vehicle_features, network_features):\n",
    "        \"\"\"\n",
    "        Preprocess raw features for model input\n",
    "        \n",
    "        Parameters:\n",
    "        - vehicle_features: Raw vehicle telemetry array\n",
    "        - network_features: Raw network traffic array\n",
    "        \n",
    "        Returns:\n",
    "        - Preprocessed tensors ready for model input\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO: Handle missing values by replacing NaN with median\n",
    "        # HINT: Use np.nan_to_num(array, nan=np.nanmedian(array))\n",
    "        vehicle_features = # TODO: Replace NaN values in vehicle features\n",
    "        network_features = # TODO: Replace NaN values in network features\n",
    "        \n",
    "        # TODO: Reshape features for scaler (expects 2D array)\n",
    "        # HINT: Use .reshape(1, -1) to convert 1D to 2D array\n",
    "        vehicle_scaled = # TODO: Transform and reshape vehicle features\n",
    "        network_scaled = # TODO: Transform and reshape network features\n",
    "        \n",
    "        # TODO: Convert to PyTorch tensors and move to device\n",
    "        # HINT: Use torch.FloatTensor(scaled_data).to(device)\n",
    "        vehicle_tensor = # TODO: Convert vehicle data to tensor\n",
    "        network_tensor = # TODO: Convert network data to tensor\n",
    "        \n",
    "        return vehicle_tensor, network_tensor\n",
    "    \n",
    "    def run_inference(self, sample_data):\n",
    "        \"\"\"\n",
    "        Run inference on a single sample\n",
    "        \n",
    "        Parameters:\n",
    "        - sample_data: Dictionary containing sample information\n",
    "        \n",
    "        Returns:\n",
    "        - prediction_result: Dictionary with prediction details\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO: Record start time for performance measurement\n",
    "        start_time = # TODO: Get current time\n",
    "        \n",
    "        # TODO: Preprocess features for model input\n",
    "        # HINT: Call self.preprocess_sample with vehicle and network features from sample_data\n",
    "        vehicle_tensor, network_tensor = # TODO: Preprocess sample features\n",
    "        \n",
    "        # TODO: Run model inference without gradient computation\n",
    "        # HINT: Use torch.no_grad() context manager\n",
    "        with # TODO: Create no_grad context:\n",
    "            # TODO: Get model outputs\n",
    "            # HINT: Call self.model(vehicle_tensor, network_tensor)\n",
    "            outputs = # TODO: Get model predictions\n",
    "            \n",
    "            # TODO: Calculate class probabilities\n",
    "            # HINT: Use F.softmax(outputs, dim=1)\n",
    "            probabilities = # TODO: Calculate softmax probabilities\n",
    "            \n",
    "            # TODO: Get predicted class index\n",
    "            # HINT: Use torch.argmax(outputs, dim=1).item()\n",
    "            predicted_class = # TODO: Get predicted class\n",
    "            \n",
    "            # TODO: Get confidence score (maximum probability)\n",
    "            # HINT: Use torch.max(probabilities).item()\n",
    "            confidence = # TODO: Get confidence score\n",
    "        \n",
    "        # TODO: Calculate inference time in milliseconds\n",
    "        # HINT: (time.time() - start_time) * 1000\n",
    "        inference_time_ms = # TODO: Calculate inference time\n",
    "        # TODO: Store inference time in history\n",
    "        self.inference_times.append(# TODO: Add inference time)\n",
    "        \n",
    "        # TODO: Create comprehensive prediction result dictionary\n",
    "        # HINT: Include all relevant information from sample_data and inference\n",
    "        prediction_result = {\n",
    "            'timestamp': # TODO: Get timestamp from sample_data\n",
    "            'sample_id': # TODO: Get sample_id from sample_data\n",
    "            'predicted_class': # TODO: Add predicted_class\n",
    "            'predicted_label': # TODO: Get class name using self.class_names\n",
    "            'confidence': # TODO: Add confidence score\n",
    "            'probabilities': # TODO: Convert probabilities to numpy (use .cpu().numpy()[0])\n",
    "            'true_class': # TODO: Get true_label from sample_data\n",
    "            'true_label': # TODO: Get true_label_name from sample_data\n",
    "            'inference_time_ms': # TODO: Add inference_time_ms\n",
    "            'is_high_confidence': # TODO: Check if confidence >= self.confidence_threshold\n",
    "            'is_correct': # TODO: Check if predicted_class == sample_data['true_label']\n",
    "        }\n",
    "        \n",
    "        # TODO: Store prediction in history\n",
    "        self.predictions_history.append(# TODO: Add prediction_result)\n",
    "        \n",
    "        return prediction_result\n",
    "    \n",
    "    def get_performance_stats(self):\n",
    "        \"\"\"Get current performance statistics\"\"\"\n",
    "        # TODO: Check if we have any inference times recorded\n",
    "        if not self.inference_times:\n",
    "            return None\n",
    "        \n",
    "        # TODO: Get recent predictions (last 100)\n",
    "        # HINT: Use list(self.predictions_history)[-100:]\n",
    "        recent_predictions = # TODO: Get last 100 predictions\n",
    "        \n",
    "        # TODO: Calculate performance statistics\n",
    "        # HINT: Use numpy functions for mean, min, max calculations\n",
    "        stats = {\n",
    "            'avg_inference_time_ms': # TODO: Calculate average inference time\n",
    "            'min_inference_time_ms': # TODO: Calculate minimum inference time\n",
    "            'max_inference_time_ms': # TODO: Calculate maximum inference time\n",
    "            'total_predictions': # TODO: Get total number of predictions\n",
    "            'recent_accuracy': # TODO: Calculate accuracy of recent predictions (mean of 'is_correct')\n",
    "            'high_confidence_rate': # TODO: Calculate rate of high confidence predictions\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# TODO: Initialize inference engine\n",
    "# HINT: Use RealTimeInferenceEngine with model, scalers, and confidence threshold\n",
    "inference_engine = # TODO: Create inference engine\n",
    "\n",
    "# TODO: Test inference engine\n",
    "print(\"\\\\nTesting inference engine:\")\n",
    "# TODO: Get test sample from data streamer\n",
    "test_sample = # TODO: Get next sample from data_streamer\n",
    "# TODO: Run inference on test sample\n",
    "test_result = # TODO: Run inference\n",
    "\n",
    "print(f\"   Sample processed in {test_result['inference_time_ms']:.2f}ms\")\n",
    "print(f\"   Prediction: {test_result['predicted_label']} (confidence: {test_result['confidence']:.3f})\")\n",
    "print(f\"   True label: {test_result['true_label']}\")\n",
    "print(f\"   Correct: {test_result['is_correct']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d6d70d",
   "metadata": {},
   "source": [
    "## Step 4: Smart Alert System - HANDS-ON PRACTICE\n",
    "\n",
    "**üéØ LEARNING OBJECTIVE:** Learn to design intelligent alerting systems with cooldown mechanisms, priority levels, and comprehensive logging.\n",
    "\n",
    "**‚ö†Ô∏è CODE COMPLETION EXERCISE:** You'll implement alert triggering logic, cooldown management, priority handling, and alert history tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmartAlertSystem:\n",
    "    \"\"\"\n",
    "    Intelligent alert system with cooldown, priority management, and logging\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, cooldown_seconds=10, min_confidence=0.7):\n",
    "        # TODO: Initialize alert system parameters\n",
    "        self.cooldown_seconds = # TODO: Store cooldown period\n",
    "        self.min_confidence = # TODO: Store minimum confidence threshold\n",
    "        \n",
    "        # TODO: Initialize alert tracking structures\n",
    "        # HINT: Use list for history, defaultdict for timestamps and counts\n",
    "        self.alert_history = # TODO: Create empty list for alert history\n",
    "        self.last_alert_time = # TODO: Create defaultdict with datetime.min default\n",
    "        self.alert_counts = # TODO: Create defaultdict with int default (0)\n",
    "        \n",
    "        # TODO: Define alert configuration for each class\n",
    "        # HINT: Dictionary with class IDs as keys, containing emoji, message, priority, color\n",
    "        self.alert_config = {\n",
    "            0: {  # Normal\n",
    "                'emoji': # TODO: Add appropriate emoji for normal operation\n",
    "                'message': # TODO: Add message for normal operation\n",
    "                'priority': # TODO: Set priority level for normal (INFO)\n",
    "                'color': # TODO: Set color code for normal (green: '\\033[92m')\n",
    "            },\n",
    "            1: {  # Physical Anomaly\n",
    "                'emoji': # TODO: Add emoji for physical anomaly (üöó)\n",
    "                'message': # TODO: Add message for vehicle system anomaly\n",
    "                'priority': # TODO: Set priority level (CRITICAL)\n",
    "                'color': # TODO: Set color code (red: '\\033[91m')\n",
    "            },\n",
    "            2: {  # Network Anomaly\n",
    "                'emoji': # TODO: Add emoji for network anomaly (üîê)\n",
    "                'message': # TODO: Add message for network security threat\n",
    "                'priority': # TODO: Set priority level (HIGH)\n",
    "                'color': # TODO: Set color code (yellow: '\\033[93m')\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        print(f\"Smart Alert System initialized:\")\n",
    "        print(f\"   Cooldown period: {cooldown_seconds} seconds\")\n",
    "        print(f\"   Minimum confidence: {min_confidence}\")\n",
    "    \n",
    "    def should_trigger_alert(self, prediction_result):\n",
    "        \"\"\"\n",
    "        Determine if an alert should be triggered based on prediction and cooldown\n",
    "        \n",
    "        Parameters:\n",
    "        - prediction_result: Dictionary from inference engine\n",
    "        \n",
    "        Returns:\n",
    "        - should_alert: Boolean indicating if alert should be triggered\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO: Extract key information from prediction result\n",
    "        predicted_class = # TODO: Get predicted_class from prediction_result\n",
    "        confidence = # TODO: Get confidence from prediction_result\n",
    "        current_time = # TODO: Get timestamp from prediction_result\n",
    "        \n",
    "        # TODO: Check confidence threshold\n",
    "        # HINT: Return False if confidence < self.min_confidence\n",
    "        if confidence < # TODO: Check confidence threshold:\n",
    "            return # TODO: Return False if confidence too low\n",
    "        \n",
    "        # TODO: Check cooldown for this alert type\n",
    "        # HINT: Get last alert time for this class and calculate time difference\n",
    "        last_alert = # TODO: Get last alert time for this predicted_class\n",
    "        # TODO: Calculate time since last alert in seconds\n",
    "        # HINT: (current_time - last_alert).total_seconds()\n",
    "        time_since_last = # TODO: Calculate time difference\n",
    "        \n",
    "        # TODO: Alert logic for anomalies (classes 1 and 2)\n",
    "        # HINT: Always alert for anomalies if cooldown has passed\n",
    "        if predicted_class != 0 and time_since_last >= # TODO: Check cooldown period:\n",
    "            return # TODO: Return True for anomalies after cooldown\n",
    "        \n",
    "        # TODO: Alert logic for normal operation (class 0)\n",
    "        # HINT: Only alert occasionally for normal operation (longer cooldown)\n",
    "        if predicted_class == 0 and time_since_last >= # TODO: Check extended cooldown (cooldown * 10):\n",
    "            return # TODO: Return True for normal operation after extended cooldown\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    def trigger_alert(self, prediction_result):\n",
    "        \"\"\"\n",
    "        Trigger an alert and log it\n",
    "        \n",
    "        Parameters:\n",
    "        - prediction_result: Dictionary from inference engine\n",
    "        \n",
    "        Returns:\n",
    "        - alert_data: Dictionary with alert information\n",
    "        \"\"\"\n",
    "        \n",
    "        # TODO: Extract prediction details\n",
    "        predicted_class = # TODO: Get predicted_class\n",
    "        # TODO: Get configuration for this alert type\n",
    "        # HINT: Use self.alert_config[predicted_class]\n",
    "        config = # TODO: Get alert configuration\n",
    "        timestamp = # TODO: Get timestamp from prediction_result\n",
    "        \n",
    "        # TODO: Create comprehensive alert data dictionary\n",
    "        # HINT: Include all relevant information for logging and display\n",
    "        alert_data = {\n",
    "            'timestamp': # TODO: Add timestamp\n",
    "            'alert_id': # TODO: Create unique alert ID (len(self.alert_history) + 1)\n",
    "            'type': # TODO: Add predicted_class\n",
    "            'label': # TODO: Get predicted_label from prediction_result\n",
    "            'confidence': # TODO: Get confidence from prediction_result\n",
    "            'priority': # TODO: Get priority from config\n",
    "            'message': # TODO: Get message from config\n",
    "            'emoji': # TODO: Get emoji from config\n",
    "            'sample_id': # TODO: Get sample_id from prediction_result\n",
    "            'inference_time_ms': # TODO: Get inference_time_ms from prediction_result\n",
    "            'is_correct': # TODO: Get is_correct from prediction_result\n",
    "        }\n",
    "        \n",
    "        # TODO: Update alert tracking\n",
    "        self.last_alert_time[predicted_class] = # TODO: Update last alert time\n",
    "        self.alert_counts[predicted_class] += 1\n",
    "        self.alert_history.append(# TODO: Add alert_data to history)\n",
    "        \n",
    "        # TODO: Display alert to console\n",
    "        # HINT: Call self._display_alert(alert_data, config)\n",
    "        self._display_alert(# TODO: Display alert)\n",
    "        \n",
    "        return alert_data\n",
    "    \n",
    "    def _display_alert(self, alert_data, config):\n",
    "        \"\"\"Display alert to console with formatting\"\"\"\n",
    "        \n",
    "        # TODO: Get display colors\n",
    "        color = # TODO: Get color from config\n",
    "        reset_color = # TODO: Set reset color code ('\\033[0m')\n",
    "        \n",
    "        # TODO: Display formatted alert information\n",
    "        # HINT: Use f-strings with color codes for formatting\n",
    "        print(f\"\\\\n{color}{'='*60}\")\n",
    "        print(f\"{alert_data['emoji']} {alert_data['priority']} ALERT #{alert_data['alert_id']}\")\n",
    "        print(f\"Time: {alert_data['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        print(f\"Type: {alert_data['label']}\")\n",
    "        print(f\"Confidence: {alert_data['confidence']:.3f}\")\n",
    "        print(f\"Message: {alert_data['message']}\")\n",
    "        # TODO: Show additional details for anomalies only\n",
    "        if alert_data['type'] != 0:  # Only show details for anomalies\n",
    "            print(f\"Sample ID: {alert_data['sample_id']}\")\n",
    "            print(f\"Processing Time: {alert_data['inference_time_ms']:.2f}ms\")\n",
    "        print(f\"{'='*60}{reset_color}\")\n",
    "    \n",
    "    def get_alert_summary(self):\n",
    "        \"\"\"Get summary of all alerts\"\"\"\n",
    "        \n",
    "        # TODO: Check if we have any alerts\n",
    "        if not self.alert_history:\n",
    "            return # TODO: Return appropriate message for no alerts\n",
    "        \n",
    "        # TODO: Calculate alert statistics\n",
    "        total_alerts = # TODO: Get total number of alerts\n",
    "        # TODO: Get recent alerts (last 5 minutes)\n",
    "        # HINT: Filter alerts where (datetime.now() - alert['timestamp']).total_seconds() < 300\n",
    "        recent_alerts = # TODO: Filter recent alerts\n",
    "        \n",
    "        # TODO: Create summary dictionary\n",
    "        summary = {\n",
    "            'total_alerts': # TODO: Add total_alerts\n",
    "            'recent_alerts': # TODO: Add count of recent alerts\n",
    "            'alert_counts': # TODO: Convert self.alert_counts to dict\n",
    "            'latest_alert': # TODO: Get latest alert or None\n",
    "        }\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def save_alerts_log(self, filename='alerts_log.csv'):\n",
    "        \"\"\"Save alerts to CSV file\"\"\"\n",
    "        \n",
    "        # TODO: Check if we have alerts to save\n",
    "        if not self.alert_history:\n",
    "            print(\"No alerts to save.\")\n",
    "            return\n",
    "        \n",
    "        # TODO: Convert alerts to DataFrame\n",
    "        # HINT: Use pd.DataFrame(self.alert_history)\n",
    "        df_alerts = # TODO: Create DataFrame from alert history\n",
    "        # TODO: Add formatted timestamp column\n",
    "        # HINT: Use dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        df_alerts['timestamp_str'] = # TODO: Format timestamps\n",
    "        \n",
    "        # TODO: Save to CSV file\n",
    "        # HINT: Use df_alerts.to_csv(filename, index=False)\n",
    "        # TODO: Save DataFrame to CSV\n",
    "        print(f\"Alerts saved to {filename} ({len(df_alerts)} alerts)\")\n",
    "        \n",
    "        return df_alerts\n",
    "\n",
    "# TODO: Initialize alert system\n",
    "# HINT: Use SmartAlertSystem with cooldown_seconds and min_confidence parameters\n",
    "alert_system = # TODO: Create alert system\n",
    "\n",
    "# TODO: Test alert system\n",
    "print(\"\\\\nTesting alert system:\")\n",
    "# TODO: Create test prediction with injected anomaly\n",
    "test_prediction = # TODO: Run inference with injected anomaly\n",
    "# TODO: Check if alert should be triggered\n",
    "if alert_system.should_trigger_alert(# TODO: Pass test_prediction):\n",
    "    # TODO: Trigger the alert\n",
    "    test_alert = # TODO: Trigger alert\n",
    "    print(f\"Alert system test completed\")\n",
    "else:\n",
    "    print(\"Alert suppressed (cooldown or confidence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb2638",
   "metadata": {},
   "source": [
    "## Step 5: Real-Time Monitoring Dashboard - HANDS-ON PRACTICE\n",
    "\n",
    "**üéØ LEARNING OBJECTIVE:** Learn to build comprehensive monitoring systems for production Edge AI applications with metrics tracking and visualization.\n",
    "\n",
    "**‚ö†Ô∏è CODE COMPLETION EXERCISE:** You'll implement metrics collection, performance tracking, status displays, and monitoring dashboards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e95582",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeMonitor:\n",
    "    \"\"\"\n",
    "    Real-time monitoring dashboard for the inference system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, update_interval=10):\n",
    "        # TODO: Initialize monitoring parameters\n",
    "        self.update_interval = # TODO: Store update interval\n",
    "        # TODO: Record start time for runtime calculations\n",
    "        # HINT: Use datetime.now()\n",
    "        self.start_time = # TODO: Record start time\n",
    "        self.monitoring_active = False\n",
    "        \n",
    "        # TODO: Initialize metrics tracking\n",
    "        # HINT: Use empty list to store metrics history\n",
    "        self.metrics_history = # TODO: Create metrics history list\n",
    "        \n",
    "        print(f\"Real-Time Monitor initialized\")\n",
    "        print(f\"   Update interval: {update_interval} seconds\")\n",
    "    \n",
    "    def log_metrics(self, inference_engine, alert_system, data_streamer):\n",
    "        \"\"\"Log current system metrics\"\"\"\n",
    "        \n",
    "        # TODO: Get current time and calculate runtime\n",
    "        current_time = # TODO: Get current datetime\n",
    "        # TODO: Calculate runtime in seconds\n",
    "        # HINT: (current_time - self.start_time).total_seconds()\n",
    "        runtime = # TODO: Calculate runtime\n",
    "        \n",
    "        # TODO: Get performance stats from inference engine\n",
    "        # HINT: Call inference_engine.get_performance_stats()\n",
    "        perf_stats = # TODO: Get performance statistics\n",
    "        \n",
    "        # TODO: Get alert summary from alert system\n",
    "        # HINT: Call alert_system.get_alert_summary()\n",
    "        alert_summary = # TODO: Get alert summary\n",
    "        \n",
    "        # TODO: Create comprehensive metrics dictionary\n",
    "        # HINT: Handle case where perf_stats might be None\n",
    "        metrics = {\n",
    "            'timestamp': # TODO: Add current_time\n",
    "            'runtime_seconds': # TODO: Add runtime\n",
    "            'total_predictions': # TODO: Get total predictions (or 0 if perf_stats is None)\n",
    "            'avg_inference_time_ms': # TODO: Get average inference time (or 0.0)\n",
    "            'recent_accuracy': # TODO: Get recent accuracy (or 0.0)\n",
    "            'high_confidence_rate': # TODO: Get high confidence rate (or 0.0)\n",
    "            'total_alerts': # TODO: Get total alerts (handle dict or string cases)\n",
    "            'recent_alerts': # TODO: Get recent alerts (handle dict or string cases)\n",
    "        }\n",
    "        \n",
    "        # TODO: Store metrics in history\n",
    "        self.metrics_history.append(# TODO: Add metrics)\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    def display_status(self, metrics):\n",
    "        \"\"\"Display current system status\"\"\"\n",
    "        \n",
    "        # TODO: Display real-time status update\n",
    "        print(f\"\\\\n{'='*50}\")\n",
    "        print(f\"üìä REAL-TIME SYSTEM STATUS\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"‚è±Ô∏è  Runtime: {metrics['runtime_seconds']:.1f} seconds\")\n",
    "        print(f\"üìà Total Predictions: {metrics['total_predictions']:,}\")\n",
    "        \n",
    "        # TODO: Display performance metrics\n",
    "        # HINT: Show inference time, accuracy, and confidence rate\n",
    "        if metrics['total_predictions'] > 0:\n",
    "            print(f\"‚ö° Avg Inference Time: {metrics['avg_inference_time_ms']:.2f}ms\")\n",
    "            print(f\"üéØ Recent Accuracy: {metrics['recent_accuracy']:.1%}\")\n",
    "            print(f\"üîí High Confidence Rate: {metrics['high_confidence_rate']:.1%}\")\n",
    "        \n",
    "        # TODO: Display alert information\n",
    "        # HINT: Show total and recent alerts\n",
    "        print(f\"üö® Total Alerts: {metrics['total_alerts']}\")\n",
    "        print(f\"‚ö†Ô∏è  Recent Alerts: {metrics['recent_alerts']}\")\n",
    "        print(f\"{'='*50}\")\n",
    "    \n",
    "    def plot_performance_metrics(self):\n",
    "        \"\"\"Plot system performance over time\"\"\"\n",
    "        \n",
    "        # TODO: Check if we have enough data for plotting\n",
    "        if len(self.metrics_history) < 2:\n",
    "            print(\"Not enough data for plotting\")\n",
    "            return\n",
    "        \n",
    "        # TODO: Convert metrics to DataFrame\n",
    "        # HINT: Use pd.DataFrame(self.metrics_history)\n",
    "        df_metrics = # TODO: Create DataFrame from metrics history\n",
    "        \n",
    "        # TODO: Create subplot figure\n",
    "        # HINT: Use plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig, axes = # TODO: Create subplots\n",
    "        fig.suptitle('Real-Time System Performance Metrics', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # TODO: Plot 1 - Inference time\n",
    "        # HINT: Plot avg_inference_time_ms vs index\n",
    "        axes[0, 0].plot(# TODO: Plot inference time)\n",
    "        axes[0, 0].set_title('Average Inference Time')\n",
    "        axes[0, 0].set_ylabel('Time (ms)')\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # TODO: Plot 2 - Accuracy\n",
    "        # HINT: Plot recent_accuracy * 100 vs index, set ylim(0, 100)\n",
    "        axes[0, 1].plot(# TODO: Plot accuracy percentage)\n",
    "        axes[0, 1].set_title('Recent Accuracy')\n",
    "        axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "        # TODO: Set y-axis limits to 0-100%\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # TODO: Plot 3 - Predictions per update\n",
    "        # HINT: Calculate difference in total_predictions between updates\n",
    "        pred_diff = # TODO: Calculate prediction differences\n",
    "        axes[1, 0].plot(# TODO: Plot prediction rate)\n",
    "        axes[1, 0].set_title('Predictions per Update')\n",
    "        axes[1, 0].set_ylabel('Count')\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # TODO: Plot 4 - Alert rate\n",
    "        # HINT: Calculate difference in total_alerts between updates\n",
    "        alert_diff = # TODO: Calculate alert differences\n",
    "        axes[1, 1].plot(# TODO: Plot alert rate)\n",
    "        axes[1, 1].set_title('Alerts per Update')\n",
    "        axes[1, 1].set_ylabel('Count')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # TODO: Apply layout and show plot\n",
    "        # HINT: Use plt.tight_layout() and plt.show()\n",
    "        # TODO: Apply tight layout\n",
    "        # TODO: Show the plot\n",
    "\n",
    "# TODO: Initialize monitor\n",
    "# HINT: Use RealTimeMonitor with update_interval parameter\n",
    "monitor = # TODO: Create monitor instance\n",
    "\n",
    "# TODO: Test monitoring\n",
    "print(\"\\\\nTesting monitoring system:\")\n",
    "# TODO: Log test metrics\n",
    "test_metrics = # TODO: Log metrics from all components\n",
    "# TODO: Display status\n",
    "monitor.display_status(# TODO: Pass test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1c26d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 6: Real-Time Simulation Execution - HANDS-ON PRACTICE\n",
    "\n",
    "**üéØ LEARNING OBJECTIVE:** Learn to build complete real-time simulation systems with dynamic scenarios, performance monitoring, and comprehensive result analysis.\n",
    "\n",
    "**‚ö†Ô∏è CODE COMPLETION EXERCISE:** You'll implement the main simulation loop, timing control, scenario management, and result collection for production Edge AI systems.\n",
    "\n",
    "def run_realtime_simulation(duration_seconds=60, samples_per_second=2, enable_anomalies=True):\n",
    "    \"\"\"\n",
    "    Run complete real-time simulation with enhanced scenario management\n",
    "    \n",
    "    Parameters:\n",
    "    - duration_seconds: How long to run the simulation\n",
    "    - samples_per_second: Sampling rate for data processing\n",
    "    - enable_anomalies: Whether to inject anomalies for testing\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Starting Real-Time Anomaly Detection Simulation\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Duration: {duration_seconds} seconds\")\n",
    "    print(f\"Sampling rate: {samples_per_second} samples/second\")\n",
    "    print(f\"Anomaly injection: {'Enabled' if enable_anomalies else 'Disabled'}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # TODO: Reset systems for fresh simulation\n",
    "    # HINT: Clear history, counts, and timestamps from alert_system\n",
    "    alert_system.alert_history.clear()\n",
    "    alert_system.alert_counts.clear()\n",
    "    alert_system.last_alert_time.clear()\n",
    "    \n",
    "    # Temporarily reduce cooldown for more alerts\n",
    "    original_cooldown = alert_system.cooldown_seconds\n",
    "    alert_system.cooldown_seconds = 2  # Reduced cooldown for demo\n",
    "    \n",
    "    # TODO: Calculate simulation parameters\n",
    "    # HINT: Calculate sample_interval from samples_per_second (1.0 / samples_per_second)\n",
    "    sample_interval = # TODO: Calculate time between samples\n",
    "    # TODO: Calculate total number of samples\n",
    "    # HINT: int(duration_seconds * samples_per_second)\n",
    "    total_samples = # TODO: Calculate total samples needed\n",
    "    # TODO: Set monitoring update interval\n",
    "    # HINT: max(8, duration_seconds // 8) for frequent monitoring\n",
    "    monitor_interval = # TODO: Calculate monitor update frequency\n",
    "    \n",
    "    # Define alert scenarios throughout the simulation\n",
    "    scenario_timeline = {\n",
    "        # Early phase: Normal operation with occasional anomalies\n",
    "        (0, 0.2): {\n",
    "            'name': 'Normal Operations',\n",
    "            'anomaly_rate': 0.15,\n",
    "            'physical_weight': 0.4,\n",
    "            'network_weight': 0.6,\n",
    "            'burst_probability': 0.05\n",
    "        },\n",
    "        # Mid-early: Coordinated attack simulation\n",
    "        (0.2, 0.35): {\n",
    "            'name': 'Coordinated Network Attack',\n",
    "            'anomaly_rate': 0.7,\n",
    "            'physical_weight': 0.2,\n",
    "            'network_weight': 0.8,\n",
    "            'burst_probability': 0.3\n",
    "        },\n",
    "        # Mid: System recovery and mixed threats\n",
    "        (0.35, 0.5): {\n",
    "            'name': 'Mixed Threat Environment',\n",
    "            'anomaly_rate': 0.45,\n",
    "            'physical_weight': 0.6,\n",
    "            'network_weight': 0.4,\n",
    "            'burst_probability': 0.15\n",
    "        },\n",
    "        # Mid-late: Physical system stress test\n",
    "        (0.5, 0.7): {\n",
    "            'name': 'Vehicle System Stress Test',\n",
    "            'anomaly_rate': 0.6,\n",
    "            'physical_weight': 0.8,\n",
    "            'network_weight': 0.2,\n",
    "            'burst_probability': 0.25\n",
    "        },\n",
    "        # Final: System degradation simulation\n",
    "        (0.7, 1.0): {\n",
    "            'name': 'System Performance Degradation',\n",
    "            'anomaly_rate': 0.3,\n",
    "            'physical_weight': 0.5,\n",
    "            'network_weight': 0.5,\n",
    "            'burst_probability': 0.1,\n",
    "            'inject_performance_issues': True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # TODO: Initialize simulation timing\n",
    "    start_time = # TODO: Record simulation start time\n",
    "    last_monitor_time = # TODO: Initialize last monitor update time\n",
    "    performance_degradation_active = False\n",
    "    burst_mode_samples = 0\n",
    "    \n",
    "    print(f\"Processing with dynamic scenario changes...\")\n",
    "    print(f\"Monitor updates every {monitor_interval} seconds\")\n",
    "    print(f\"\\\\nSimulation starting...\")\n",
    "    \n",
    "    try:\n",
    "        for sample_num in range(total_samples):\n",
    "            # TODO: Record loop start time for timing control\n",
    "            loop_start = # TODO: Get loop start time\n",
    "            \n",
    "            # TODO: Calculate progress ratio\n",
    "            # HINT: sample_num / total_samples\n",
    "            progress_ratio = # TODO: Calculate progress as ratio 0-1\n",
    "            \n",
    "            # TODO: Determine current scenario based on progress\n",
    "            current_scenario = None\n",
    "            for (start_ratio, end_ratio), scenario in scenario_timeline.items():\n",
    "                if start_ratio <= progress_ratio < end_ratio:\n",
    "                    current_scenario = scenario\n",
    "                    break\n",
    "            \n",
    "            # TODO: Handle case where no scenario found (use last scenario)\n",
    "            if current_scenario is None:\n",
    "                current_scenario = # TODO: Use last scenario as fallback\n",
    "            \n",
    "            # TODO: Implement burst mode logic for consecutive anomalies\n",
    "            inject_anomaly = None\n",
    "            if burst_mode_samples > 0:\n",
    "                # TODO: Continue burst mode\n",
    "                # HINT: Choose anomaly type based on scenario weights\n",
    "                inject_anomaly = # TODO: Choose anomaly type during burst\n",
    "                burst_mode_samples -= 1\n",
    "            elif np.random.random() < current_scenario.get('burst_probability', 0):\n",
    "                # TODO: Start new burst (3-7 consecutive anomalies)\n",
    "                burst_mode_samples = # TODO: Set random burst length (3-8 samples)\n",
    "                inject_anomaly = # TODO: Choose initial burst anomaly type\n",
    "            elif np.random.random() < current_scenario['anomaly_rate']:\n",
    "                # TODO: Regular anomaly injection\n",
    "                inject_anomaly = # TODO: Choose regular anomaly type\n",
    "            \n",
    "            # TODO: Get sample and run inference\n",
    "            # HINT: Use data_streamer.get_next_sample and inference_engine.run_inference\n",
    "            sample_data = # TODO: Get next sample with potential anomaly injection\n",
    "            prediction_result = # TODO: Run inference on sample\n",
    "            \n",
    "            # TODO: Simulate performance degradation in final phase\n",
    "            if current_scenario.get('inject_performance_issues', False):\n",
    "                # TODO: Randomly degrade inference time\n",
    "                if np.random.random() < 0.2:\n",
    "                    prediction_result['inference_time_ms'] *= # TODO: Multiply by random factor (2-4x)\n",
    "                \n",
    "                # TODO: Occasionally flip predictions to simulate model degradation\n",
    "                if np.random.random() < 0.12:\n",
    "                    original_class = prediction_result['predicted_class']\n",
    "                    # TODO: Choose alternative class\n",
    "                    alternatives = # TODO: Create list of other classes\n",
    "                    new_class = # TODO: Choose random alternative class\n",
    "                    # TODO: Update prediction result with degraded prediction\n",
    "                    prediction_result['predicted_class'] = new_class\n",
    "                    prediction_result['predicted_label'] = inference_engine.class_names[new_class]\n",
    "                    prediction_result['confidence'] *= # TODO: Reduce confidence (0.4-0.8x)\n",
    "                    prediction_result['is_correct'] = # TODO: Recalculate correctness\n",
    "            \n",
    "            # TODO: Enhanced alert triggering with performance monitoring\n",
    "            should_alert = # TODO: Check if standard alert should trigger\n",
    "            \n",
    "            # TODO: Additional alert conditions for performance and confidence\n",
    "            if not should_alert:\n",
    "                # TODO: Alert on high inference time (performance issue)\n",
    "                if prediction_result['inference_time_ms'] > 50:  # Threshold for concern\n",
    "                    should_alert = # TODO: Set alert flag for performance issue\n",
    "                    prediction_result['performance_alert'] = True\n",
    "                \n",
    "                # TODO: Alert on confidence drops for anomalies\n",
    "                elif prediction_result['confidence'] < 0.4 and prediction_result['predicted_class'] != 0:\n",
    "                    should_alert = # TODO: Set alert flag for low confidence\n",
    "                    prediction_result['low_confidence_alert'] = True\n",
    "            \n",
    "            # TODO: Trigger alerts with enhanced metadata\n",
    "            if should_alert:\n",
    "                alert_data = # TODO: Trigger alert\n",
    "                \n",
    "                # TODO: Add scenario context to alert\n",
    "                alert_data['scenario'] = # TODO: Add current scenario name\n",
    "                if hasattr(prediction_result, 'performance_alert'):\n",
    "                    alert_data['alert_subtype'] = 'Performance Issue'\n",
    "                elif hasattr(prediction_result, 'low_confidence_alert'):\n",
    "                    alert_data['alert_subtype'] = 'Low Confidence'\n",
    "                \n",
    "                # TODO: Special handling for burst alerts\n",
    "                if burst_mode_samples > 0:\n",
    "                    alert_data['burst_alert'] = True\n",
    "                    alert_data['remaining_burst'] = burst_mode_samples\n",
    "            \n",
    "            # TODO: Monitor updates with scenario info\n",
    "            current_time = # TODO: Get current time\n",
    "            if current_time - last_monitor_time >= monitor_interval:\n",
    "                # TODO: Log metrics and display status\n",
    "                metrics = # TODO: Log system metrics\n",
    "                # TODO: Display current status\n",
    "                \n",
    "                # TODO: Display current scenario information\n",
    "                print(f\"Current Scenario: {current_scenario['name']}\")\n",
    "                if burst_mode_samples > 0:\n",
    "                    print(f\"üî• BURST MODE ACTIVE: {burst_mode_samples} samples remaining\")\n",
    "                print(f\"Anomaly Rate: {current_scenario['anomaly_rate']:.0%}\")\n",
    "                \n",
    "                last_monitor_time = current_time\n",
    "            \n",
    "            # TODO: Maintain precise timing\n",
    "            # HINT: Calculate sleep time to maintain sample_interval\n",
    "            elapsed = # TODO: Calculate loop elapsed time\n",
    "            sleep_time = # TODO: Calculate required sleep time\n",
    "            if sleep_time > 0:\n",
    "                # TODO: Sleep to maintain timing\n",
    "                pass\n",
    "            \n",
    "            # TODO: Progress indicator with scenario transitions\n",
    "            if (sample_num + 1) % max(1, (total_samples // 15)) == 0:\n",
    "                progress = (sample_num + 1) / total_samples * 100\n",
    "                elapsed_sim_time = # TODO: Calculate total simulation elapsed time\n",
    "                print(f\"Progress: {progress:.0f}% ({elapsed_sim_time:.1f}s) - {current_scenario['name']}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\\\nüõë Simulation interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        # TODO: Restore original cooldown\n",
    "        alert_system.cooldown_seconds = # TODO: Restore original cooldown\n",
    "    \n",
    "    # TODO: Calculate final comprehensive statistics\n",
    "    total_runtime = # TODO: Calculate total simulation runtime\n",
    "    final_metrics = # TODO: Log final metrics\n",
    "    \n",
    "    print(f\"\\\\nüéØ Comprehensive Simulation Complete!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total runtime: {total_runtime:.2f} seconds\")\n",
    "    print(f\"Samples processed: {final_metrics['total_predictions']}\")\n",
    "    print(f\"Processing rate: {final_metrics['total_predictions']/total_runtime:.1f} samples/sec\")\n",
    "    print(f\"Average inference: {final_metrics['avg_inference_time_ms']:.2f}ms\")\n",
    "    print(f\"Recent accuracy: {final_metrics['recent_accuracy']:.1%}\")\n",
    "    \n",
    "    # TODO: Detailed alert analysis\n",
    "    alert_summary = # TODO: Get comprehensive alert summary\n",
    "    if isinstance(alert_summary, dict):\n",
    "        print(f\"\\\\nüìä Comprehensive Alert Analysis:\")\n",
    "        print(f\"   üö® Total alerts generated: {alert_summary['total_alerts']}\")\n",
    "        print(f\"   ‚è∞ Recent alerts (5 min): {alert_summary['recent_alerts']}\")\n",
    "        \n",
    "        # TODO: Alert breakdown by type\n",
    "        class_names = {0: 'Normal Operation', 1: 'Physical Anomaly', 2: 'Network Anomaly'}\n",
    "        print(f\"\\\\n   Alert Distribution:\")\n",
    "        for alert_type, count in alert_summary['alert_counts'].items():\n",
    "            percentage = (count / alert_summary['total_alerts']) * 100 if alert_summary['total_alerts'] > 0 else 0\n",
    "            print(f\"     {class_names.get(alert_type, f'Type {alert_type}')}: {count} alerts ({percentage:.1f}%)\")\n",
    "        \n",
    "        # TODO: Calculate and display alert rate\n",
    "        if alert_summary['total_alerts'] > 0:\n",
    "            alert_rate = # TODO: Calculate alerts per minute\n",
    "            print(f\"\\\\n   üìà Alert Rate: {alert_rate:.1f} alerts/minute\")\n",
    "    \n",
    "    # TODO: Save comprehensive results\n",
    "    alerts_df = # TODO: Save alerts to file\n",
    "    \n",
    "    # TODO: Enhanced performance plotting\n",
    "    if len(monitor.metrics_history) > 1:\n",
    "        # TODO: Plot performance metrics\n",
    "        pass\n",
    "    \n",
    "    # TODO: Alert timeline visualization\n",
    "    if len(alert_system.alert_history) > 0:\n",
    "        # TODO: Plot alert timeline (will be implemented in Step 7)\n",
    "        pass\n",
    "    \n",
    "    return final_metrics, alerts_df\n",
    "\n",
    "print(\"‚úÖ Comprehensive Alert Simulation Function Defined\")\n",
    "print(\"   Ready for multi-scenario simulation with dynamic timeline visualization\")\n",
    "\n",
    "# TODO: Execute the simulation\n",
    "print(\"Ready to start real-time simulation!\")\n",
    "print(\"   The simulation will process streaming data and detect anomalies in real-time.\")\n",
    "print(\"   Press Ctrl+C to stop the simulation early.\")\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "\n",
    "# TODO: Run simulation with specified parameters\n",
    "# HINT: Call run_realtime_simulation with duration_seconds, samples_per_second, enable_anomalies\n",
    "simulation_results, alerts_log = # TODO: Execute simulation with 30s duration, 1 sample/sec, anomalies enabled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aca3c1",
   "metadata": {},
   "source": [
    "## Step 7: Alert Analysis and Visualization\n",
    "\n",
    "Analyze the generated alerts and create visualizations for system performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4d3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comprehensive_alert_simulation(duration_seconds=90, samples_per_second=4):\n",
    "    \"\"\"\n",
    "    Comprehensive alert simulation with diverse scenarios and patterns\n",
    "    \n",
    "    This enhanced simulation includes:\n",
    "    - Multiple alert scenarios (burst patterns, gradual escalation, system health)\n",
    "    - Temporal anomaly patterns (coordinated attacks, system degradation)\n",
    "    - Performance-based alerts (latency spikes, accuracy drops)\n",
    "    - Mixed confidence levels for realistic alert variety\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Starting Comprehensive Multi-Scenario Alert Simulation\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Duration: {duration_seconds} seconds\")\n",
    "    print(f\"High-frequency sampling: {samples_per_second} samples/second\")\n",
    "    print(f\"Expected ~{duration_seconds * samples_per_second} total samples\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Reset all systems\n",
    "    alert_system.alert_history.clear()\n",
    "    alert_system.alert_counts.clear()\n",
    "    alert_system.last_alert_time.clear()\n",
    "    \n",
    "    # Temporarily reduce cooldown for more alerts\n",
    "    original_cooldown = alert_system.cooldown_seconds\n",
    "    alert_system.cooldown_seconds = 2  # Reduced cooldown for demo\n",
    "    \n",
    "    # Enhanced simulation parameters\n",
    "    sample_interval = 1.0 / samples_per_second\n",
    "    total_samples = int(duration_seconds * samples_per_second)\n",
    "    monitor_interval = max(8, duration_seconds // 8)  # Frequent monitoring\n",
    "    \n",
    "    # Define alert scenarios throughout the simulation\n",
    "    scenario_timeline = {\n",
    "        # Early phase: Normal operation with occasional anomalies\n",
    "        (0, 0.2): {\n",
    "            'name': 'Normal Operations',\n",
    "            'anomaly_rate': 0.15,\n",
    "            'physical_weight': 0.4,\n",
    "            'network_weight': 0.6,\n",
    "            'burst_probability': 0.05\n",
    "        },\n",
    "        # Mid-early: Coordinated attack simulation\n",
    "        (0.2, 0.35): {\n",
    "            'name': 'Coordinated Network Attack',\n",
    "            'anomaly_rate': 0.7,\n",
    "            'physical_weight': 0.2,\n",
    "            'network_weight': 0.8,\n",
    "            'burst_probability': 0.3\n",
    "        },\n",
    "        # Mid: System recovery and mixed threats\n",
    "        (0.35, 0.5): {\n",
    "            'name': 'Mixed Threat Environment',\n",
    "            'anomaly_rate': 0.45,\n",
    "            'physical_weight': 0.6,\n",
    "            'network_weight': 0.4,\n",
    "            'burst_probability': 0.15\n",
    "        },\n",
    "        # Mid-late: Physical system stress test\n",
    "        (0.5, 0.7): {\n",
    "            'name': 'Vehicle System Stress Test',\n",
    "            'anomaly_rate': 0.6,\n",
    "            'physical_weight': 0.8,\n",
    "            'network_weight': 0.2,\n",
    "            'burst_probability': 0.25\n",
    "        },\n",
    "        # Final: System degradation simulation\n",
    "        (0.7, 1.0): {\n",
    "            'name': 'System Performance Degradation',\n",
    "            'anomaly_rate': 0.3,\n",
    "            'physical_weight': 0.5,\n",
    "            'network_weight': 0.5,\n",
    "            'burst_probability': 0.1,\n",
    "            'inject_performance_issues': True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    last_monitor_time = start_time\n",
    "    performance_degradation_active = False\n",
    "    burst_mode_samples = 0\n",
    "    \n",
    "    print(f\"Processing with dynamic scenario changes...\")\n",
    "    print(f\"Monitor updates every {monitor_interval} seconds\")\n",
    "    print(f\"\\nSimulation starting...\")\n",
    "    \n",
    "    try:\n",
    "        for sample_num in range(total_samples):\n",
    "            loop_start = time.time()\n",
    "            progress_ratio = sample_num / total_samples\n",
    "            \n",
    "            # Determine current scenario\n",
    "            current_scenario = None\n",
    "            for (start_ratio, end_ratio), scenario in scenario_timeline.items():\n",
    "                if start_ratio <= progress_ratio < end_ratio:\n",
    "                    current_scenario = scenario\n",
    "                    break\n",
    "            \n",
    "            if current_scenario is None:\n",
    "                current_scenario = list(scenario_timeline.values())[-1]  # Use last scenario\n",
    "            \n",
    "            # Burst mode logic\n",
    "            inject_anomaly = None\n",
    "            if burst_mode_samples > 0:\n",
    "                # Continue burst\n",
    "                inject_anomaly = np.random.choice([1, 2], \n",
    "                    p=[current_scenario['physical_weight'], current_scenario['network_weight']])\n",
    "                burst_mode_samples -= 1\n",
    "            elif np.random.random() < current_scenario.get('burst_probability', 0):\n",
    "                # Start new burst (3-7 consecutive anomalies)\n",
    "                burst_mode_samples = np.random.randint(3, 8)\n",
    "                inject_anomaly = np.random.choice([1, 2], \n",
    "                    p=[current_scenario['physical_weight'], current_scenario['network_weight']])\n",
    "            elif np.random.random() < current_scenario['anomaly_rate']:\n",
    "                # Regular anomaly injection\n",
    "                inject_anomaly = np.random.choice([1, 2], \n",
    "                    p=[current_scenario['physical_weight'], current_scenario['network_weight']])\n",
    "            \n",
    "            # Get sample and run inference\n",
    "            sample_data = data_streamer.get_next_sample(inject_anomaly=inject_anomaly)\n",
    "            prediction_result = inference_engine.run_inference(sample_data)\n",
    "            \n",
    "            # Simulate performance degradation in final phase\n",
    "            if current_scenario.get('inject_performance_issues', False):\n",
    "                # Randomly degrade inference time\n",
    "                if np.random.random() < 0.2:\n",
    "                    prediction_result['inference_time_ms'] *= np.random.uniform(2.0, 4.0)\n",
    "                \n",
    "                # Occasionally flip predictions to simulate model degradation\n",
    "                if np.random.random() < 0.12:\n",
    "                    original_class = prediction_result['predicted_class']\n",
    "                    alternatives = [c for c in [0, 1, 2] if c != original_class]\n",
    "                    new_class = np.random.choice(alternatives)\n",
    "                    prediction_result['predicted_class'] = new_class\n",
    "                    prediction_result['predicted_label'] = inference_engine.class_names[new_class]\n",
    "                    prediction_result['confidence'] *= np.random.uniform(0.4, 0.8)  # Lower confidence\n",
    "                    prediction_result['is_correct'] = (new_class == sample_data['true_label'])\n",
    "            \n",
    "            # Enhanced alert triggering with performance monitoring\n",
    "            should_alert = alert_system.should_trigger_alert(prediction_result)\n",
    "            \n",
    "            # Additional alert conditions\n",
    "            if not should_alert:\n",
    "                # Alert on high inference time (performance issue)\n",
    "                if prediction_result['inference_time_ms'] > 50:  # Threshold for concern\n",
    "                    should_alert = True\n",
    "                    # Modify alert for performance issue\n",
    "                    prediction_result['performance_alert'] = True\n",
    "                \n",
    "                # Alert on confidence drops\n",
    "                elif prediction_result['confidence'] < 0.4 and prediction_result['predicted_class'] != 0:\n",
    "                    should_alert = True\n",
    "                    prediction_result['low_confidence_alert'] = True\n",
    "            \n",
    "            # Trigger alerts\n",
    "            if should_alert:\n",
    "                alert_data = alert_system.trigger_alert(prediction_result)\n",
    "                \n",
    "                # Add scenario context to alert\n",
    "                alert_data['scenario'] = current_scenario['name']\n",
    "                if hasattr(prediction_result, 'performance_alert'):\n",
    "                    alert_data['alert_subtype'] = 'Performance Issue'\n",
    "                elif hasattr(prediction_result, 'low_confidence_alert'):\n",
    "                    alert_data['alert_subtype'] = 'Low Confidence'\n",
    "                \n",
    "                # Special handling for burst alerts\n",
    "                if burst_mode_samples > 0:\n",
    "                    alert_data['burst_alert'] = True\n",
    "                    alert_data['remaining_burst'] = burst_mode_samples\n",
    "            \n",
    "            # Monitor updates with scenario info\n",
    "            current_time = time.time()\n",
    "            if current_time - last_monitor_time >= monitor_interval:\n",
    "                metrics = monitor.log_metrics(inference_engine, alert_system, data_streamer)\n",
    "                monitor.display_status(metrics)\n",
    "                \n",
    "                # Display current scenario\n",
    "                print(f\"Current Scenario: {current_scenario['name']}\")\n",
    "                if burst_mode_samples > 0:\n",
    "                    print(f\"üî• BURST MODE ACTIVE: {burst_mode_samples} samples remaining\")\n",
    "                print(f\"Anomaly Rate: {current_scenario['anomaly_rate']:.0%}\")\n",
    "                \n",
    "                last_monitor_time = current_time\n",
    "            \n",
    "            # Maintain timing\n",
    "            elapsed = time.time() - loop_start\n",
    "            sleep_time = max(0, sample_interval - elapsed)\n",
    "            if sleep_time > 0:\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            # Progress with scenario transitions\n",
    "            if (sample_num + 1) % max(1, (total_samples // 15)) == 0:\n",
    "                progress = (sample_num + 1) / total_samples * 100\n",
    "                elapsed_sim_time = time.time() - start_time\n",
    "                print(f\"Progress: {progress:.0f}% ({elapsed_sim_time:.1f}s) - {current_scenario['name']}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\nüõë Simulation interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        # Restore original cooldown\n",
    "        alert_system.cooldown_seconds = original_cooldown\n",
    "    \n",
    "    # Final comprehensive statistics\n",
    "    total_runtime = time.time() - start_time\n",
    "    final_metrics = monitor.log_metrics(inference_engine, alert_system, data_streamer)\n",
    "    \n",
    "    print(f\"\\nüéØ Comprehensive Simulation Complete!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total runtime: {total_runtime:.2f} seconds\")\n",
    "    print(f\"Samples processed: {final_metrics['total_predictions']}\")\n",
    "    print(f\"Processing rate: {final_metrics['total_predictions']/total_runtime:.1f} samples/sec\")\n",
    "    print(f\"Average inference: {final_metrics['avg_inference_time_ms']:.2f}ms\")\n",
    "    print(f\"Recent accuracy: {final_metrics['recent_accuracy']:.1%}\")\n",
    "    \n",
    "    # Detailed alert analysis\n",
    "    alert_summary = alert_system.get_alert_summary()\n",
    "    if isinstance(alert_summary, dict):\n",
    "        print(f\"\\nüìä Comprehensive Alert Analysis:\")\n",
    "        print(f\"   üö® Total alerts generated: {alert_summary['total_alerts']}\")\n",
    "        print(f\"   ‚è∞ Recent alerts (5 min): {alert_summary['recent_alerts']}\")\n",
    "        \n",
    "        # Alert breakdown by type\n",
    "        class_names = {0: 'Normal Operation', 1: 'Physical Anomaly', 2: 'Network Anomaly'}\n",
    "        print(f\"\\n   Alert Distribution:\")\n",
    "        for alert_type, count in alert_summary['alert_counts'].items():\n",
    "            percentage = (count / alert_summary['total_alerts']) * 100 if alert_summary['total_alerts'] > 0 else 0\n",
    "            print(f\"     {class_names.get(alert_type, f'Type {alert_type}')}: {count} alerts ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Alert rate analysis\n",
    "        if alert_summary['total_alerts'] > 0:\n",
    "            alert_rate = alert_summary['total_alerts'] / (total_runtime / 60)  # alerts per minute\n",
    "            print(f\"\\n   üìà Alert Rate: {alert_rate:.1f} alerts/minute\")\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    alerts_df = alert_system.save_alerts_log()\n",
    "    \n",
    "    # Enhanced performance plotting\n",
    "    if len(monitor.metrics_history) > 1:\n",
    "        monitor.plot_performance_metrics()\n",
    "    \n",
    "    # Alert timeline visualization\n",
    "    if len(alert_system.alert_history) > 0:\n",
    "        plot_alert_timeline()\n",
    "    \n",
    "    return final_metrics, alerts_df\n",
    "\n",
    "print(\"‚úÖ Comprehensive Alert Simulation Function Defined\")\n",
    "print(\"   Ready for multi-scenario simulation with dynamic timeline visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alert_timeline():\n",
    "    \"\"\"Create a timeline visualization of alerts with adaptive time binning and full timeline support\"\"\"\n",
    "    \n",
    "    if not alert_system.alert_history:\n",
    "        print(\"No alerts to plot\")\n",
    "        return\n",
    "    \n",
    "    df_alerts = pd.DataFrame(alert_system.alert_history)\n",
    "    \n",
    "    # Display alert timeline info\n",
    "    total_alerts = len(df_alerts)\n",
    "    duration_seconds = (df_alerts['timestamp'].max() - df_alerts['timestamp'].min()).total_seconds()\n",
    "    print(f\"\\nüìä Alert Timeline Analysis:\")\n",
    "    print(f\"   Total alerts: {total_alerts}\")\n",
    "    print(f\"   Simulation duration: {duration_seconds:.1f} seconds ({duration_seconds/60:.1f} minutes)\")\n",
    "    print(f\"   Alert rate: {total_alerts/(duration_seconds/60):.1f} alerts/minute\")\n",
    "    \n",
    "    # Create timeline plot with improved sizing for full timeline\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12))  # Wider plot for full timeline\n",
    "    \n",
    "    # Alert timeline (top plot) - Fixed to show full timeline\n",
    "    class_colors = {0: 'green', 1: 'red', 2: 'orange'}\n",
    "    class_names = {0: 'Normal', 1: 'Physical', 2: 'Network'}\n",
    "    \n",
    "    # Calculate time in minutes for better readability\n",
    "    for alert_type in df_alerts['type'].unique():\n",
    "        type_alerts = df_alerts[df_alerts['type'] == alert_type]\n",
    "        times = [(t - df_alerts['timestamp'].min()).total_seconds() / 60 for t in type_alerts['timestamp']]\n",
    "        \n",
    "        ax1.scatter(times, [alert_type] * len(times), \n",
    "                   c=class_colors[alert_type], label=class_names[alert_type], \n",
    "                   alpha=0.7, s=60)\n",
    "    \n",
    "    # Set x-axis to show full timeline\n",
    "    max_time_minutes = duration_seconds / 60\n",
    "    ax1.set_xlim(0, max_time_minutes)\n",
    "    ax1.set_xlabel('Time (minutes)')\n",
    "    ax1.set_ylabel('Alert Type')\n",
    "    ax1.set_title(f'Alert Timeline - Full {duration_seconds:.1f} Second Simulation')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set y-axis ticks to show alert type labels\n",
    "    ax1.set_yticks([0, 1, 2])\n",
    "    ax1.set_yticklabels(['Normal', 'Physical', 'Network'])\n",
    "    \n",
    "    # Alert frequency over time (bottom plot) - Improved binning with full timeline coverage\n",
    "    total_duration_minutes = duration_seconds / 60\n",
    "    \n",
    "    if total_duration_minutes <= 2:\n",
    "        # For short simulations, use 10-second bins\n",
    "        bin_size_seconds = 10\n",
    "        time_unit = \"10-sec intervals\"\n",
    "    elif total_duration_minutes <= 5:\n",
    "        # For medium simulations, use 15-second bins  \n",
    "        bin_size_seconds = 15\n",
    "        time_unit = \"15-sec intervals\"\n",
    "    else:\n",
    "        # For long simulations, use 30-second bins\n",
    "        bin_size_seconds = 30\n",
    "        time_unit = \"30-sec intervals\"\n",
    "    \n",
    "    # Create time bins covering the full simulation duration\n",
    "    num_bins = int(np.ceil(duration_seconds / bin_size_seconds))\n",
    "    df_alerts['time_bin'] = ((df_alerts['timestamp'] - df_alerts['timestamp'].min()).dt.total_seconds() / bin_size_seconds).astype(int)\n",
    "    \n",
    "    # Count alerts per bin\n",
    "    alerts_per_bin = df_alerts.groupby('time_bin').size()\n",
    "    \n",
    "    # Create complete range of bins (including empty ones) for full timeline\n",
    "    all_bins = range(0, num_bins + 1)\n",
    "    alerts_counts = [alerts_per_bin.get(i, 0) for i in all_bins]\n",
    "    \n",
    "    # Create bar chart with full timeline\n",
    "    ax2.bar(all_bins, alerts_counts, alpha=0.7, color='skyblue', edgecolor='navy', linewidth=0.5)\n",
    "    ax2.set_xlabel(f'Time ({time_unit})')\n",
    "    ax2.set_ylabel('Alerts per Interval')\n",
    "    ax2.set_title(f'Alert Frequency Distribution - Full Timeline ({time_unit})')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set x-axis labels for better readability (show key time points)\n",
    "    if len(all_bins) <= 20:  # Show all labels if not too crowded\n",
    "        tick_step = max(1, len(all_bins) // 10)\n",
    "        ax2.set_xticks(all_bins[::tick_step])\n",
    "        ax2.set_xticklabels([f\"{i*bin_size_seconds}s\" for i in all_bins[::tick_step]], rotation=45)\n",
    "    else:  # Show fewer labels for very long simulations\n",
    "        tick_step = max(1, len(all_bins) // 8)\n",
    "        ax2.set_xticks(all_bins[::tick_step])\n",
    "        ax2.set_xticklabels([f\"{i*bin_size_seconds}s\" for i in all_bins[::tick_step]], rotation=45)\n",
    "    \n",
    "    # Ensure the plot shows the full timeline\n",
    "    ax2.set_xlim(-0.5, num_bins + 0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional statistics\n",
    "    print(f\"\\nüìà Timeline Statistics:\")\n",
    "    print(f\"   Time bins: {num_bins} ({bin_size_seconds}s each)\")\n",
    "    print(f\"   Peak alerts in single interval: {max(alerts_counts)} alerts\")\n",
    "    print(f\"   Average alerts per interval: {np.mean(alerts_counts):.1f}\")\n",
    "    print(f\"   Empty intervals: {alerts_counts.count(0)}/{num_bins} ({alerts_counts.count(0)/num_bins*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a436cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the comprehensive simulation with full 75-second duration\n",
    "comprehensive_results, comprehensive_alerts = run_comprehensive_alert_simulation(\n",
    "    duration_seconds=75,  # Full 75 seconds for complete timeline\n",
    "    samples_per_second=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ff6969",
   "metadata": {},
   "source": [
    "## Step 7: Alert Analysis and Visualization\n",
    "\n",
    "Analyze the generated alerts and create visualizations for system performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_comprehensive_alert_simulation(duration_seconds=90, samples_per_second=4):\n",
    "    \"\"\"\n",
    "    Comprehensive alert simulation with diverse scenarios and patterns\n",
    "    \n",
    "    This enhanced simulation includes:\n",
    "    - Multiple alert scenarios (burst patterns, gradual escalation, system health)\n",
    "    - Temporal anomaly patterns (coordinated attacks, system degradation)\n",
    "    - Performance-based alerts (latency spikes, accuracy drops)\n",
    "    - Mixed confidence levels for realistic alert variety\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Starting Comprehensive Multi-Scenario Alert Simulation\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Duration: {duration_seconds} seconds\")\n",
    "    print(f\"High-frequency sampling: {samples_per_second} samples/second\")\n",
    "    print(f\"Expected ~{duration_seconds * samples_per_second} total samples\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Reset all systems\n",
    "    alert_system.alert_history.clear()\n",
    "    alert_system.alert_counts.clear()\n",
    "    alert_system.last_alert_time.clear()\n",
    "    \n",
    "    # Temporarily reduce cooldown for more alerts\n",
    "    original_cooldown = alert_system.cooldown_seconds\n",
    "    alert_system.cooldown_seconds = 2  # Reduced cooldown for demo\n",
    "    \n",
    "    # Enhanced simulation parameters\n",
    "    sample_interval = 1.0 / samples_per_second\n",
    "    total_samples = int(duration_seconds * samples_per_second)\n",
    "    monitor_interval = max(8, duration_seconds // 8)  # Frequent monitoring\n",
    "    \n",
    "    # Define alert scenarios throughout the simulation\n",
    "    scenario_timeline = {\n",
    "        # Early phase: Normal operation with occasional anomalies\n",
    "        (0, 0.2): {\n",
    "            'name': 'Normal Operations',\n",
    "            'anomaly_rate': 0.15,\n",
    "            'physical_weight': 0.4,\n",
    "            'network_weight': 0.6,\n",
    "            'burst_probability': 0.05\n",
    "        },\n",
    "        # Mid-early: Coordinated attack simulation\n",
    "        (0.2, 0.35): {\n",
    "            'name': 'Coordinated Network Attack',\n",
    "            'anomaly_rate': 0.7,\n",
    "            'physical_weight': 0.2,\n",
    "            'network_weight': 0.8,\n",
    "            'burst_probability': 0.3\n",
    "        },\n",
    "        # Mid: System recovery and mixed threats\n",
    "        (0.35, 0.5): {\n",
    "            'name': 'Mixed Threat Environment',\n",
    "            'anomaly_rate': 0.45,\n",
    "            'physical_weight': 0.6,\n",
    "            'network_weight': 0.4,\n",
    "            'burst_probability': 0.15\n",
    "        },\n",
    "        # Mid-late: Physical system stress test\n",
    "        (0.5, 0.7): {\n",
    "            'name': 'Vehicle System Stress Test',\n",
    "            'anomaly_rate': 0.6,\n",
    "            'physical_weight': 0.8,\n",
    "            'network_weight': 0.2,\n",
    "            'burst_probability': 0.25\n",
    "        },\n",
    "        # Final: System degradation simulation\n",
    "        (0.7, 1.0): {\n",
    "            'name': 'System Performance Degradation',\n",
    "            'anomaly_rate': 0.3,\n",
    "            'physical_weight': 0.5,\n",
    "            'network_weight': 0.5,\n",
    "            'burst_probability': 0.1,\n",
    "            'inject_performance_issues': True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    start_time = time.time()\n",
    "    last_monitor_time = start_time\n",
    "    performance_degradation_active = False\n",
    "    burst_mode_samples = 0\n",
    "    \n",
    "    print(f\"Processing with dynamic scenario changes...\")\n",
    "    print(f\"Monitor updates every {monitor_interval} seconds\")\n",
    "    print(f\"\\nSimulation starting...\")\n",
    "    \n",
    "    try:\n",
    "        for sample_num in range(total_samples):\n",
    "            loop_start = time.time()\n",
    "            progress_ratio = sample_num / total_samples\n",
    "            \n",
    "            # Determine current scenario\n",
    "            current_scenario = None\n",
    "            for (start_ratio, end_ratio), scenario in scenario_timeline.items():\n",
    "                if start_ratio <= progress_ratio < end_ratio:\n",
    "                    current_scenario = scenario\n",
    "                    break\n",
    "            \n",
    "            if current_scenario is None:\n",
    "                current_scenario = list(scenario_timeline.values())[-1]  # Use last scenario\n",
    "            \n",
    "            # Burst mode logic\n",
    "            inject_anomaly = None\n",
    "            if burst_mode_samples > 0:\n",
    "                # Continue burst\n",
    "                inject_anomaly = np.random.choice([1, 2], \n",
    "                    p=[current_scenario['physical_weight'], current_scenario['network_weight']])\n",
    "                burst_mode_samples -= 1\n",
    "            elif np.random.random() < current_scenario.get('burst_probability', 0):\n",
    "                # Start new burst (3-7 consecutive anomalies)\n",
    "                burst_mode_samples = np.random.randint(3, 8)\n",
    "                inject_anomaly = np.random.choice([1, 2], \n",
    "                    p=[current_scenario['physical_weight'], current_scenario['network_weight']])\n",
    "            elif np.random.random() < current_scenario['anomaly_rate']:\n",
    "                # Regular anomaly injection\n",
    "                inject_anomaly = np.random.choice([1, 2], \n",
    "                    p=[current_scenario['physical_weight'], current_scenario['network_weight']])\n",
    "            \n",
    "            # Get sample and run inference\n",
    "            sample_data = data_streamer.get_next_sample(inject_anomaly=inject_anomaly)\n",
    "            prediction_result = inference_engine.run_inference(sample_data)\n",
    "            \n",
    "            # Simulate performance degradation in final phase\n",
    "            if current_scenario.get('inject_performance_issues', False):\n",
    "                # Randomly degrade inference time\n",
    "                if np.random.random() < 0.2:\n",
    "                    prediction_result['inference_time_ms'] *= np.random.uniform(2.0, 4.0)\n",
    "                \n",
    "                # Occasionally flip predictions to simulate model degradation\n",
    "                if np.random.random() < 0.12:\n",
    "                    original_class = prediction_result['predicted_class']\n",
    "                    alternatives = [c for c in [0, 1, 2] if c != original_class]\n",
    "                    new_class = np.random.choice(alternatives)\n",
    "                    prediction_result['predicted_class'] = new_class\n",
    "                    prediction_result['predicted_label'] = inference_engine.class_names[new_class]\n",
    "                    prediction_result['confidence'] *= np.random.uniform(0.4, 0.8)  # Lower confidence\n",
    "                    prediction_result['is_correct'] = (new_class == sample_data['true_label'])\n",
    "            \n",
    "            # Enhanced alert triggering with performance monitoring\n",
    "            should_alert = alert_system.should_trigger_alert(prediction_result)\n",
    "            \n",
    "            # Additional alert conditions\n",
    "            if not should_alert:\n",
    "                # Alert on high inference time (performance issue)\n",
    "                if prediction_result['inference_time_ms'] > 50:  # Threshold for concern\n",
    "                    should_alert = True\n",
    "                    # Modify alert for performance issue\n",
    "                    prediction_result['performance_alert'] = True\n",
    "                \n",
    "                # Alert on confidence drops\n",
    "                elif prediction_result['confidence'] < 0.4 and prediction_result['predicted_class'] != 0:\n",
    "                    should_alert = True\n",
    "                    prediction_result['low_confidence_alert'] = True\n",
    "            \n",
    "            # Trigger alerts\n",
    "            if should_alert:\n",
    "                alert_data = alert_system.trigger_alert(prediction_result)\n",
    "                \n",
    "                # Add scenario context to alert\n",
    "                alert_data['scenario'] = current_scenario['name']\n",
    "                if hasattr(prediction_result, 'performance_alert'):\n",
    "                    alert_data['alert_subtype'] = 'Performance Issue'\n",
    "                elif hasattr(prediction_result, 'low_confidence_alert'):\n",
    "                    alert_data['alert_subtype'] = 'Low Confidence'\n",
    "                \n",
    "                # Special handling for burst alerts\n",
    "                if burst_mode_samples > 0:\n",
    "                    alert_data['burst_alert'] = True\n",
    "                    alert_data['remaining_burst'] = burst_mode_samples\n",
    "            \n",
    "            # Monitor updates with scenario info\n",
    "            current_time = time.time()\n",
    "            if current_time - last_monitor_time >= monitor_interval:\n",
    "                metrics = monitor.log_metrics(inference_engine, alert_system, data_streamer)\n",
    "                monitor.display_status(metrics)\n",
    "                \n",
    "                # Display current scenario\n",
    "                print(f\"Current Scenario: {current_scenario['name']}\")\n",
    "                if burst_mode_samples > 0:\n",
    "                    print(f\"üî• BURST MODE ACTIVE: {burst_mode_samples} samples remaining\")\n",
    "                print(f\"Anomaly Rate: {current_scenario['anomaly_rate']:.0%}\")\n",
    "                \n",
    "                last_monitor_time = current_time\n",
    "            \n",
    "            # Maintain timing\n",
    "            elapsed = time.time() - loop_start\n",
    "            sleep_time = max(0, sample_interval - elapsed)\n",
    "            if sleep_time > 0:\n",
    "                time.sleep(sleep_time)\n",
    "            \n",
    "            # Progress with scenario transitions\n",
    "            if (sample_num + 1) % max(1, (total_samples // 15)) == 0:\n",
    "                progress = (sample_num + 1) / total_samples * 100\n",
    "                elapsed_sim_time = time.time() - start_time\n",
    "                print(f\"Progress: {progress:.0f}% ({elapsed_sim_time:.1f}s) - {current_scenario['name']}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\nüõë Simulation interrupted by user\")\n",
    "    \n",
    "    finally:\n",
    "        # Restore original cooldown\n",
    "        alert_system.cooldown_seconds = original_cooldown\n",
    "    \n",
    "    # Final comprehensive statistics\n",
    "    total_runtime = time.time() - start_time\n",
    "    final_metrics = monitor.log_metrics(inference_engine, alert_system, data_streamer)\n",
    "    \n",
    "    print(f\"\\nüéØ Comprehensive Simulation Complete!\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total runtime: {total_runtime:.2f} seconds\")\n",
    "    print(f\"Samples processed: {final_metrics['total_predictions']}\")\n",
    "    print(f\"Processing rate: {final_metrics['total_predictions']/total_runtime:.1f} samples/sec\")\n",
    "    print(f\"Average inference: {final_metrics['avg_inference_time_ms']:.2f}ms\")\n",
    "    print(f\"Recent accuracy: {final_metrics['recent_accuracy']:.1%}\")\n",
    "    \n",
    "    # Detailed alert analysis\n",
    "    alert_summary = alert_system.get_alert_summary()\n",
    "    if isinstance(alert_summary, dict):\n",
    "        print(f\"\\nüìä Comprehensive Alert Analysis:\")\n",
    "        print(f\"   üö® Total alerts generated: {alert_summary['total_alerts']}\")\n",
    "        print(f\"   ‚è∞ Recent alerts (5 min): {alert_summary['recent_alerts']}\")\n",
    "        \n",
    "        # Alert breakdown by type\n",
    "        class_names = {0: 'Normal Operation', 1: 'Physical Anomaly', 2: 'Network Anomaly'}\n",
    "        print(f\"\\n   Alert Distribution:\")\n",
    "        for alert_type, count in alert_summary['alert_counts'].items():\n",
    "            percentage = (count / alert_summary['total_alerts']) * 100 if alert_summary['total_alerts'] > 0 else 0\n",
    "            print(f\"     {class_names.get(alert_type, f'Type {alert_type}')}: {count} alerts ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Alert rate analysis\n",
    "        if alert_summary['total_alerts'] > 0:\n",
    "            alert_rate = alert_summary['total_alerts'] / (total_runtime / 60)  # alerts per minute\n",
    "            print(f\"\\n   üìà Alert Rate: {alert_rate:.1f} alerts/minute\")\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    alerts_df = alert_system.save_alerts_log()\n",
    "    \n",
    "    # Enhanced performance plotting\n",
    "    if len(monitor.metrics_history) > 1:\n",
    "        monitor.plot_performance_metrics()\n",
    "    \n",
    "    # Alert timeline visualization\n",
    "    if len(alert_system.alert_history) > 0:\n",
    "        plot_alert_timeline()\n",
    "    \n",
    "    return final_metrics, alerts_df\n",
    "\n",
    "print(\"‚úÖ Comprehensive Alert Simulation Function Defined\")\n",
    "print(\"   Ready for multi-scenario simulation with dynamic timeline visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f83e083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alert_timeline():\n",
    "    \"\"\"Create a timeline visualization of alerts with adaptive time binning and full timeline support\"\"\"\n",
    "    \n",
    "    if not alert_system.alert_history:\n",
    "        print(\"No alerts to plot\")\n",
    "        return\n",
    "    \n",
    "    df_alerts = pd.DataFrame(alert_system.alert_history)\n",
    "    \n",
    "    # Display alert timeline info\n",
    "    total_alerts = len(df_alerts)\n",
    "    duration_seconds = (df_alerts['timestamp'].max() - df_alerts['timestamp'].min()).total_seconds()\n",
    "    print(f\"\\nüìä Alert Timeline Analysis:\")\n",
    "    print(f\"   Total alerts: {total_alerts}\")\n",
    "    print(f\"   Simulation duration: {duration_seconds:.1f} seconds ({duration_seconds/60:.1f} minutes)\")\n",
    "    print(f\"   Alert rate: {total_alerts/(duration_seconds/60):.1f} alerts/minute\")\n",
    "    \n",
    "    # Create timeline plot with improved sizing for full timeline\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12))  # Wider plot for full timeline\n",
    "    \n",
    "    # Alert timeline (top plot) - Fixed to show full timeline\n",
    "    class_colors = {0: 'green', 1: 'red', 2: 'orange'}\n",
    "    class_names = {0: 'Normal', 1: 'Physical', 2: 'Network'}\n",
    "    \n",
    "    # Calculate time in minutes for better readability\n",
    "    for alert_type in df_alerts['type'].unique():\n",
    "        type_alerts = df_alerts[df_alerts['type'] == alert_type]\n",
    "        times = [(t - df_alerts['timestamp'].min()).total_seconds() / 60 for t in type_alerts['timestamp']]\n",
    "        \n",
    "        ax1.scatter(times, [alert_type] * len(times), \n",
    "                   c=class_colors[alert_type], label=class_names[alert_type], \n",
    "                   alpha=0.7, s=60)\n",
    "    \n",
    "    # Set x-axis to show full timeline\n",
    "    max_time_minutes = duration_seconds / 60\n",
    "    ax1.set_xlim(0, max_time_minutes)\n",
    "    ax1.set_xlabel('Time (minutes)')\n",
    "    ax1.set_ylabel('Alert Type')\n",
    "    ax1.set_title(f'Alert Timeline - Full {duration_seconds:.1f} Second Simulation')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set y-axis ticks to show alert type labels\n",
    "    ax1.set_yticks([0, 1, 2])\n",
    "    ax1.set_yticklabels(['Normal', 'Physical', 'Network'])\n",
    "    \n",
    "    # Alert frequency over time (bottom plot) - Improved binning with full timeline coverage\n",
    "    total_duration_minutes = duration_seconds / 60\n",
    "    \n",
    "    if total_duration_minutes <= 2:\n",
    "        # For short simulations, use 10-second bins\n",
    "        bin_size_seconds = 10\n",
    "        time_unit = \"10-sec intervals\"\n",
    "    elif total_duration_minutes <= 5:\n",
    "        # For medium simulations, use 15-second bins  \n",
    "        bin_size_seconds = 15\n",
    "        time_unit = \"15-sec intervals\"\n",
    "    else:\n",
    "        # For long simulations, use 30-second bins\n",
    "        bin_size_seconds = 30\n",
    "        time_unit = \"30-sec intervals\"\n",
    "    \n",
    "    # Create time bins covering the full simulation duration\n",
    "    num_bins = int(np.ceil(duration_seconds / bin_size_seconds))\n",
    "    df_alerts['time_bin'] = ((df_alerts['timestamp'] - df_alerts['timestamp'].min()).dt.total_seconds() / bin_size_seconds).astype(int)\n",
    "    \n",
    "    # Count alerts per bin\n",
    "    alerts_per_bin = df_alerts.groupby('time_bin').size()\n",
    "    \n",
    "    # Create complete range of bins (including empty ones) for full timeline\n",
    "    all_bins = range(0, num_bins + 1)\n",
    "    alerts_counts = [alerts_per_bin.get(i, 0) for i in all_bins]\n",
    "    \n",
    "    # Create bar chart with full timeline\n",
    "    ax2.bar(all_bins, alerts_counts, alpha=0.7, color='skyblue', edgecolor='navy', linewidth=0.5)\n",
    "    ax2.set_xlabel(f'Time ({time_unit})')\n",
    "    ax2.set_ylabel('Alerts per Interval')\n",
    "    ax2.set_title(f'Alert Frequency Distribution - Full Timeline ({time_unit})')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Set x-axis labels for better readability (show key time points)\n",
    "    if len(all_bins) <= 20:  # Show all labels if not too crowded\n",
    "        tick_step = max(1, len(all_bins) // 10)\n",
    "        ax2.set_xticks(all_bins[::tick_step])\n",
    "        ax2.set_xticklabels([f\"{i*bin_size_seconds}s\" for i in all_bins[::tick_step]], rotation=45)\n",
    "    else:  # Show fewer labels for very long simulations\n",
    "        tick_step = max(1, len(all_bins) // 8)\n",
    "        ax2.set_xticks(all_bins[::tick_step])\n",
    "        ax2.set_xticklabels([f\"{i*bin_size_seconds}s\" for i in all_bins[::tick_step]], rotation=45)\n",
    "    \n",
    "    # Ensure the plot shows the full timeline\n",
    "    ax2.set_xlim(-0.5, num_bins + 0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Additional statistics\n",
    "    print(f\"\\nüìà Timeline Statistics:\")\n",
    "    print(f\"   Time bins: {num_bins} ({bin_size_seconds}s each)\")\n",
    "    print(f\"   Peak alerts in single interval: {max(alerts_counts)} alerts\")\n",
    "    print(f\"   Average alerts per interval: {np.mean(alerts_counts):.1f}\")\n",
    "    print(f\"   Empty intervals: {alerts_counts.count(0)}/{num_bins} ({alerts_counts.count(0)/num_bins*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f436f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the comprehensive simulation with full 75-second duration\n",
    "comprehensive_results, comprehensive_alerts = run_comprehensive_alert_simulation(\n",
    "    duration_seconds=75,  # Full 75 seconds for complete timeline\n",
    "    samples_per_second=4\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
