{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "722567bb",
   "metadata": {},
   "source": [
    "# Workshop 3.1: Fine-Grained Pruning for Efficient Inference - Hands-On Practice\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this notebook, you will:\n",
    "- Understand what fine-grained (unstructured) pruning is and why it's important for edge AI\n",
    "- Learn about magnitude-based pruning (remove smallest weights)\n",
    "- **PRACTICE** implementing post-training pruning with PyTorch\n",
    "- Compare model sparsity, speed, and accuracy trade-offs\n",
    "- Complete hands-on coding exercises\n",
    "\n",
    "## What is Fine-Grained Pruning?\n",
    "Fine-grained pruning (also called unstructured pruning) removes individual weights from neural networks based on their magnitude. Unlike structured pruning that removes entire channels or filters, fine-grained pruning can remove any weight regardless of its position, creating sparse networks with irregular patterns.\n",
    "\n",
    "This workshop focuses specifically on magnitude-based pruning, which provides:\n",
    "- Significant model compression (up to 90% sparsity)\n",
    "- Recoverable accuracy with fine-tuning\n",
    "- Simple implementation using PyTorch\n",
    "- Clear understanding of pruning trade-offs\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1506.02626\n",
    "\n",
    "\n",
    "---\n",
    "**ðŸ”¥ HANDS-ON PRACTICE**: This notebook contains code completion exercises marked with `# TODO:` comments. Fill in the missing code to complete the pruning workflow!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad9741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torchvision import models\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7153431",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb4d7cf",
   "metadata": {},
   "source": [
    "### Understanding CIFAR-10: Why This Dataset?\n",
    "\n",
    "CIFAR-10 is perfect for learning pruning because:\n",
    "- **Small images (32Ã—32)** - Fast training and testing\n",
    "- **Realistic challenge** - 10 different object classes\n",
    "- **Edge AI relevant** - Similar to mobile camera applications\n",
    "- **Resource-friendly** - Doesn't require powerful hardware\n",
    "\n",
    "The small image size makes it ideal for:\n",
    "- Mobile device deployment\n",
    "- Edge computing scenarios\n",
    "- Real-time inference applications\n",
    "- Learning optimization techniques like pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacdfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = DataLoader(trainset, batch_size=256, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = DataLoader(testset, batch_size=200, shuffle=False, num_workers=2)\n",
    "\n",
    "# CIFAR-10 classes\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "print(f\"Training samples: {len(trainset)}\")\n",
    "print(f\"Test samples: {len(testset)}\")\n",
    "print(f\"Classes: {classes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73404627",
   "metadata": {},
   "source": [
    "## Step 2: Load Pre-trained MobileNetV2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0951055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the MobileNetV2 adaptation function\n",
    "def create_mobilenetv2_cifar10(num_classes=10, pretrained=True):\n",
    "    \"\"\"\n",
    "    Create MobileNetV2 adapted for CIFAR-10\n",
    "    CIFAR-10 images are 32x32, smaller than ImageNet's 224x224\n",
    "    \"\"\"\n",
    "    # TODO: Load pre-trained MobileNetV2 using models.mobilenet_v2()\n",
    "    model = # Your code here\n",
    "    \n",
    "    # Modify the first convolution layer for smaller input size\n",
    "    # Original: stride=2, now stride=1 to preserve spatial dimensions\n",
    "    model.features[0][0] = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    \n",
    "    # TODO: Modify classifier for CIFAR-10 (10 classes instead of 1000)\n",
    "    # HINT: model.classifier[1] should be a Linear layer with model.last_channel input features\n",
    "    model.classifier[1] = # Your code here\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create model instance\n",
    "model = create_mobilenetv2_cifar10(num_classes=10, pretrained=True).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"MobileNetV2 loaded with {total_params:,} total parameters\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model adapted for CIFAR-10 (32x32 images, 10 classes)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddc3a4a",
   "metadata": {},
   "source": [
    "## Step 3: Train the Original Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6440cdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the training function\n",
    "def train_model(model, trainloader, testloader, epochs=10, learning_rate=0.001):\n",
    "    # TODO: Define criterion (loss function) - use CrossEntropyLoss\n",
    "    criterion = # Your code here\n",
    "    \n",
    "    # TODO: Define optimizer - use Adam with the given learning rate\n",
    "    optimizer = # Your code here\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Training loop with progress bar\n",
    "        pbar = tqdm(trainloader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        for batch_idx, (inputs, labels) in enumerate(pbar):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # TODO: Zero gradients\n",
    "            # Your code here\n",
    "            \n",
    "            # TODO: Forward pass\n",
    "            outputs = # Your code here\n",
    "            \n",
    "            # TODO: Calculate loss\n",
    "            loss = # Your code here\n",
    "            \n",
    "            # TODO: Backward pass\n",
    "            # Your code here\n",
    "            \n",
    "            # TODO: Update weights\n",
    "            # Your code here\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'Loss': f'{running_loss/(batch_idx+1):.3f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        epoch_acc = 100. * correct / total\n",
    "        \n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accuracies.append(epoch_acc)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%')\n",
    "    \n",
    "    return train_losses, train_accuracies\n",
    "\n",
    "# Train the model\n",
    "print(\"Training original model...\")\n",
    "train_losses, train_accuracies = train_model(model, trainloader, testloader, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2915f90d",
   "metadata": {},
   "source": [
    "## Step 4: Evaluate Original Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f506881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the evaluation function\n",
    "def evaluate_model(model, testloader, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Evaluate model accuracy and measure inference time\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Measure inference time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(testloader, desc=f'Evaluating {model_name}'):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # TODO: Forward pass\n",
    "            outputs = # Your code here\n",
    "            \n",
    "            # TODO: Get predictions\n",
    "            _, predicted = # Your code here\n",
    "            \n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    inference_time = end_time - start_time\n",
    "    \n",
    "    accuracy = 100. * correct / total\n",
    "    print(f'{model_name} - Accuracy: {accuracy:.2f}%, Inference Time: {inference_time:.2f}s')\n",
    "    \n",
    "    return accuracy, inference_time\n",
    "\n",
    "# TODO: Complete the sparsity calculation function\n",
    "def calculate_sparsity(model):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of zero weights in the model\n",
    "    \"\"\"\n",
    "    total_params = 0\n",
    "    zero_params = 0\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # Check if the module has been pruned (has weight_mask)\n",
    "            if hasattr(module, 'weight_mask'):\n",
    "                # TODO: Calculate effective weight (weight * mask)\n",
    "                effective_weight = # Your code here\n",
    "                total_params += effective_weight.numel()\n",
    "                zero_params += (effective_weight == 0).sum().item()\n",
    "            else:\n",
    "                # If not pruned, count normally\n",
    "                total_params += module.weight.numel()\n",
    "                zero_params += (module.weight == 0).sum().item()\n",
    "    \n",
    "    sparsity = 100.0 * zero_params / total_params if total_params > 0 else 0.0\n",
    "    return sparsity\n",
    "\n",
    "# Evaluate original model performance (baseline)\n",
    "print(\"Evaluating original model performance...\")\n",
    "original_accuracy, original_time = evaluate_model(model, testloader, \"Original\")\n",
    "original_sparsity = calculate_sparsity(model)\n",
    "\n",
    "print(f\"\\nOriginal Model Summary:\")\n",
    "print(f\"  Accuracy: {original_accuracy:.2f}%\")\n",
    "print(f\"  Inference time: {original_time:.2f}s\")\n",
    "print(f\"  Sparsity: {original_sparsity:.2f}%\")\n",
    "print(f\"  This will be our baseline for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a39924c",
   "metadata": {},
   "source": [
    "## Step 5: Analyze Weight Distributions\n",
    "\n",
    "Before pruning, let's analyze the weight distributions to understand which weights are candidates for removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2143fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the weight collection function\n",
    "def collect_weights(model):\n",
    "    \"\"\"\n",
    "    Collect all weights from the model for analysis\n",
    "    \"\"\"\n",
    "    all_weights = []\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # TODO: Get weights and flatten them\n",
    "            # HINT: use module.weight.data.cpu().flatten().numpy()\n",
    "            weights = # Your code here\n",
    "            all_weights.extend(weights)\n",
    "    \n",
    "    return np.array(all_weights)\n",
    "\n",
    "# Collect weights from the trained model\n",
    "all_weights = collect_weights(model)\n",
    "\n",
    "print(f\"Weight Distribution Analysis:\")\n",
    "print(f\"  Total weights: {len(all_weights):,}\")\n",
    "print(f\"  Mean: {np.mean(all_weights):.6f}\")\n",
    "print(f\"  Std: {np.std(all_weights):.6f}\")\n",
    "print(f\"  Min: {np.min(all_weights):.6f}\")\n",
    "print(f\"  Max: {np.max(all_weights):.6f}\")\n",
    "\n",
    "# Analyze small weights (candidates for pruning)\n",
    "small_weights = np.abs(all_weights) < 0.01\n",
    "print(f\"  Weights with |w| < 0.01: {small_weights.sum():,} ({small_weights.mean()*100:.1f}%)\")\n",
    "print(f\"  These small weights are good candidates for pruning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77621272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize weight distribution\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "# Plot 1: Full weight distribution\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(all_weights, bins=100, alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title('Weight Distribution - Full Range')\n",
    "plt.xlabel('Weight Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Zoomed-in distribution around zero\n",
    "plt.subplot(1, 2, 2)\n",
    "close_to_zero = all_weights[np.abs(all_weights) < 0.1]\n",
    "plt.hist(close_to_zero, bins=50, alpha=0.7, color='red', edgecolor='black')\n",
    "plt.title('Weight Distribution - Near Zero (|w| < 0.1)')\n",
    "plt.xlabel('Weight Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nKey Insight:\")\n",
    "print(f\"  Many weights are close to zero, suggesting high pruning potential!\")\n",
    "print(f\"  Magnitude-based pruning will remove the smallest weights first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7b05a1",
   "metadata": {},
   "source": [
    "## Step 6: Apply Magnitude-Based Pruning\n",
    "\n",
    "Magnitude-based pruning removes weights with the smallest absolute values. This is based on the assumption that small weights contribute less to the model's output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93c0e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the magnitude-based pruning function\n",
    "def apply_magnitude_pruning(model, pruning_ratio):\n",
    "    \"\"\"\n",
    "    Apply magnitude-based pruning to all Conv2d and Linear layers\n",
    "    \"\"\"\n",
    "    print(f\"Applying {pruning_ratio:.0%} magnitude-based pruning...\")\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "            # TODO: Apply L1 (magnitude-based) unstructured pruning\n",
    "            # HINT: use prune.l1_unstructured(module, name='weight', amount=pruning_ratio)\n",
    "            # Your code here\n",
    "            \n",
    "            print(f\"  Pruned layer: {name}\")\n",
    "    \n",
    "    print(f\"Magnitude-based pruning complete!\")\n",
    "    return model\n",
    "\n",
    "# Set pruning ratio (start with 70% pruning)\n",
    "PRUNING_RATIO = 0.7\n",
    "\n",
    "# Create a copy of the model for pruning\n",
    "pruned_model = copy.deepcopy(model)\n",
    "\n",
    "# Apply pruning\n",
    "pruned_model = apply_magnitude_pruning(pruned_model, PRUNING_RATIO)\n",
    "\n",
    "print(f\"\\nPruning Applied:\")\n",
    "print(f\"  Pruning ratio: {PRUNING_RATIO:.0%}\")\n",
    "print(f\"  This means {PRUNING_RATIO:.0%} of weights are set to zero\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe1017",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate Pruned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764452a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the pruned model\n",
    "print(\"Evaluating pruned model...\")\n",
    "pruned_accuracy, pruned_time = evaluate_model(pruned_model, testloader, f\"{PRUNING_RATIO:.0%} Pruned\")\n",
    "pruned_sparsity = calculate_sparsity(pruned_model)\n",
    "\n",
    "# Compare with original model\n",
    "accuracy_drop = original_accuracy - pruned_accuracy\n",
    "\n",
    "print(f\"\\nPruned Model Results:\")\n",
    "print(f\"  Accuracy: {pruned_accuracy:.2f}% (drop: {accuracy_drop:.2f}%)\")\n",
    "print(f\"  Inference time: {pruned_time:.2f}s\")\n",
    "print(f\"  Sparsity: {pruned_sparsity:.1f}%\")\n",
    "\n",
    "print(f\"\\nComparison:\")\n",
    "print(f\"  Original accuracy: {original_accuracy:.2f}%\")\n",
    "print(f\"  Pruned accuracy: {pruned_accuracy:.2f}%\")\n",
    "print(f\"  Accuracy drop: {accuracy_drop:.2f}%\")\n",
    "print(f\"  Sparsity achieved: {pruned_sparsity:.1f}%\")\n",
    "print(f\"  --> Fine-tuning can help recover some lost accuracy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819c11eb",
   "metadata": {},
   "source": [
    "## Step 8: Fine-tune the Pruned Model\n",
    "\n",
    "Fine-tuning helps the remaining weights adapt to compensate for the pruned weights, often recovering much of the lost accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the fine-tuning function\n",
    "def fine_tune_pruned_model(model, trainloader, testloader, epochs=5, learning_rate=0.0001):\n",
    "    \"\"\"\n",
    "    Fine-tune a pruned model to recover accuracy\n",
    "    \"\"\"\n",
    "    print(f\"Fine-tuning pruned model for {epochs} epochs...\")\n",
    "    \n",
    "    # TODO: Set up optimizer and loss function\n",
    "    # HINT: Use a smaller learning rate for fine-tuning\n",
    "    optimizer = # Your code here\n",
    "    criterion = # Your code here\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        progress_bar = tqdm(trainloader, desc=f'Fine-tune Epoch {epoch+1}/{epochs}')\n",
    "        \n",
    "        for inputs, labels in progress_bar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # TODO: Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = # Your code here\n",
    "            loss = # Your code here\n",
    "            \n",
    "            # TODO: Backward pass\n",
    "            # Your code here\n",
    "            # Your code here\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'Loss': f'{running_loss/len(trainloader):.4f}',\n",
    "                'Acc': f'{100.*correct/total:.2f}%'\n",
    "            })\n",
    "        \n",
    "        epoch_accuracy = 100. * correct / total\n",
    "        print(f'Epoch {epoch+1}: Training accuracy: {epoch_accuracy:.2f}%')\n",
    "    \n",
    "    print(f\"Fine-tuning complete!\")\n",
    "    return model\n",
    "\n",
    "# Fine-tune the pruned model\n",
    "finetuned_model = copy.deepcopy(pruned_model)\n",
    "finetuned_model = fine_tune_pruned_model(finetuned_model, trainloader, testloader, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c4231f",
   "metadata": {},
   "source": [
    "## Step 9: Evaluate Fine-tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da40517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the fine-tuned model\n",
    "print(\"Evaluating fine-tuned model...\")\n",
    "finetuned_accuracy, finetuned_time = evaluate_model(finetuned_model, testloader, f\"{PRUNING_RATIO:.0%} Pruned + Fine-tuned\")\n",
    "finetuned_sparsity = calculate_sparsity(finetuned_model)\n",
    "\n",
    "# Calculate recovery\n",
    "recovery = finetuned_accuracy - pruned_accuracy\n",
    "final_accuracy_drop = original_accuracy - finetuned_accuracy\n",
    "\n",
    "print(f\"\\nFine-tuned Model Results:\")\n",
    "print(f\"  Accuracy: {finetuned_accuracy:.2f}%\")\n",
    "print(f\"  Inference time: {finetuned_time:.2f}s\")\n",
    "print(f\"  Sparsity: {finetuned_sparsity:.1f}%\")\n",
    "\n",
    "print(f\"\\nFinal Comparison:\")\n",
    "print(f\"  Original accuracy: {original_accuracy:.2f}%\")\n",
    "print(f\"  Pruned accuracy: {pruned_accuracy:.2f}%\")\n",
    "print(f\"  Fine-tuned accuracy: {finetuned_accuracy:.2f}%\")\n",
    "print(f\"  Recovery from fine-tuning: +{recovery:.2f}%\")\n",
    "print(f\"  Final accuracy drop: {final_accuracy_drop:.2f}%\")\n",
    "print(f\"  Sparsity achieved: {finetuned_sparsity:.1f}%\")\n",
    "\n",
    "# Check if we achieved good compression with acceptable accuracy\n",
    "target_accuracy = 85.0\n",
    "if finetuned_accuracy >= target_accuracy:\n",
    "    print(f\"\\nSUCCESS: Achieved {finetuned_accuracy:.2f}% accuracy (target: â‰¥{target_accuracy}%)\")\n",
    "    print(f\"   Model compressed to {100-finetuned_sparsity:.1f}% of original size!\")\n",
    "else:\n",
    "    print(f\"\\nTarget not met: {finetuned_accuracy:.2f}% vs {target_accuracy}% target\")\n",
    "    print(f\"   Try a lower pruning ratio or more fine-tuning epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b692b31a",
   "metadata": {},
   "source": [
    "## Step 10: Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f1790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: Accuracy comparison\n",
    "models = ['Original', f'{PRUNING_RATIO:.0%} Pruned', f'{PRUNING_RATIO:.0%} Pruned\\n+ Fine-tuned']\n",
    "accuracies = [original_accuracy, pruned_accuracy, finetuned_accuracy]\n",
    "colors = ['blue', 'red', 'green']\n",
    "\n",
    "bars1 = ax1.bar(models, accuracies, color=colors, alpha=0.7)\n",
    "ax1.axhline(y=85, color='red', linestyle='--', alpha=0.8, label='Target (85%)')\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.set_title('Model Accuracy Comparison')\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, acc in zip(bars1, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "            f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# Plot 2: Sparsity comparison\n",
    "sparsities = [original_sparsity, pruned_sparsity, finetuned_sparsity]\n",
    "\n",
    "bars2 = ax2.bar(models, sparsities, color=colors, alpha=0.7)\n",
    "ax2.set_ylabel('Sparsity (%)')\n",
    "ax2.set_title('Model Sparsity Comparison')\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, sparsity in zip(bars2, sparsities):\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "            f'{sparsity:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nVisualization Summary:\")\n",
    "print(f\"  Left chart: Shows accuracy impact and recovery from fine-tuning\")\n",
    "print(f\"  Right chart: Shows sparsity achieved (higher = more compressed)\")\n",
    "print(f\"  Goal: High sparsity with acceptable accuracy!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746739cc",
   "metadata": {},
   "source": [
    "## Step 11: Experiment with Different Pruning Ratios\n",
    "\n",
    "Try different pruning ratios to find the best trade-off between compression and accuracy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5de33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Experiment with different pruning ratios\n",
    "# Change the value below to try different compression levels\n",
    "EXPERIMENT_RATIO = 0.5  # Try: 0.5, 0.6, 0.8, 0.9\n",
    "\n",
    "print(f\"\\nExperimenting with {EXPERIMENT_RATIO:.0%} pruning...\")\n",
    "\n",
    "# Create experimental model\n",
    "experimental_model = copy.deepcopy(model)\n",
    "experimental_model = apply_magnitude_pruning(experimental_model, EXPERIMENT_RATIO)\n",
    "\n",
    "# Evaluate experimental model\n",
    "exp_accuracy, exp_time = evaluate_model(experimental_model, testloader, f\"{EXPERIMENT_RATIO:.0%} Experimental\")\n",
    "exp_sparsity = calculate_sparsity(experimental_model)\n",
    "\n",
    "# Compare with the original 70% pruning\n",
    "print(f\"\\nExperimental Results ({EXPERIMENT_RATIO:.0%} pruning):\")\n",
    "print(f\"  Accuracy: {exp_accuracy:.2f}%\")\n",
    "print(f\"  Sparsity: {exp_sparsity:.1f}%\")\n",
    "print(f\"  Accuracy drop: {original_accuracy - exp_accuracy:.2f}%\")\n",
    "\n",
    "print(f\"\\nComparison with {PRUNING_RATIO:.0%} pruning:\")\n",
    "print(f\"  {EXPERIMENT_RATIO:.0%} pruning: {exp_accuracy:.2f}% accuracy, {exp_sparsity:.1f}% sparsity\")\n",
    "print(f\"  {PRUNING_RATIO:.0%} pruning: {pruned_accuracy:.2f}% accuracy, {pruned_sparsity:.1f}% sparsity\")\n",
    "\n",
    "if exp_accuracy > pruned_accuracy:\n",
    "    print(f\"  â†’ {EXPERIMENT_RATIO:.0%} pruning gives better accuracy!\")\n",
    "elif exp_sparsity > pruned_sparsity:\n",
    "    print(f\"  â†’ {EXPERIMENT_RATIO:.0%} pruning gives better compression!\")\n",
    "else:\n",
    "    print(f\"  â†’ {PRUNING_RATIO:.0%} pruning seems to be a good balance\")\n",
    "\n",
    "print(f\"\\nTry different ratios to find your optimal trade-off!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea67d499",
   "metadata": {},
   "source": [
    "## Step 12: Summary and Key Insights\n",
    "\n",
    "Congratulations! You've successfully implemented magnitude-based pruning with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2872c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MAGNITUDE-BASED PRUNING WORKSHOP COMPLETE!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nFINAL RESULTS SUMMARY:\")\n",
    "print(f\"  Original Model: {original_accuracy:.2f}% accuracy, {original_sparsity:.1f}% sparsity\")\n",
    "print(f\"  {PRUNING_RATIO:.0%} Pruned: {pruned_accuracy:.2f}% accuracy, {pruned_sparsity:.1f}% sparsity\")\n",
    "print(f\"  Fine-tuned: {finetuned_accuracy:.2f}% accuracy, {finetuned_sparsity:.1f}% sparsity\")\n",
    "print(f\"  Recovery: +{recovery:.2f}% accuracy from fine-tuning\")\n",
    "print(f\"  Final compression: {finetuned_sparsity:.1f}% sparsity achieved\")\n",
    "\n",
    "print(f\"\\nKEY INSIGHTS:\")\n",
    "print(f\"  â€¢ Magnitude-based pruning removes the smallest weights first\")\n",
    "print(f\"  â€¢ {PRUNING_RATIO:.0%} pruning achieved {finetuned_sparsity:.1f}% sparsity with {final_accuracy_drop:.2f}% accuracy drop\")\n",
    "print(f\"  â€¢ Fine-tuning is crucial for recovering accuracy after pruning\")\n",
    "print(f\"  â€¢ There's a trade-off between compression and accuracy\")\n",
    "print(f\"  â€¢ Different pruning ratios offer different compression-accuracy trade-offs\")\n",
    "\n",
    "print(f\"\\nPRACTICAL APPLICATIONS:\")\n",
    "print(f\"  â€¢ Mobile and edge device deployment\")\n",
    "print(f\"  â€¢ Reducing memory bandwidth requirements\")\n",
    "print(f\"  â€¢ Enabling larger models on resource-constrained devices\")\n",
    "print(f\"  â€¢ Battery life improvement in mobile applications\")\n",
    "\n",
    "print(f\"\\nNEXT STEPS:\")\n",
    "print(f\"  â€¢ Try structured pruning for actual inference speedup\")\n",
    "print(f\"  â€¢ Combine pruning with quantization for maximum compression\")\n",
    "print(f\"  â€¢ Explore gradual pruning during training\")\n",
    "print(f\"  â€¢ Test on different model architectures\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(\"Thank you for completing the Magnitude-Based Pruning workshop!\")\n",
    "print(\"Continue exploring model compression techniques for efficient AI deployment.\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
